{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Manual_Practico_Machine_Learning_COMENTADO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be656734",
      "metadata": {
        "id": "be656734"
      },
      "source": [
        "# Manual Pr√°ctico de Machine Learning con Python\n",
        "\n",
        "Este cuaderno contiene una gu√≠a completa para aprender y practicar los principales conceptos y t√©cnicas de Machine Learning con Python. Est√° organizado por bloques tem√°ticos. Cada bloque incluye:\n",
        "\n",
        "- Una **explicaci√≥n breve**\n",
        "- Un **ejemplo ejecutable**\n",
        "- Un **ejercicio pr√°ctico guiado**\n",
        "- Una **reflexi√≥n sobre para qu√© sirve y cu√°ndo se usa**\n",
        "\n",
        "> **Sigue el orden o navega por el √≠ndice seg√∫n tus intereses.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéì Consejo importante para aprender Machine Learning\n",
        "\n",
        "No intentes memorizar el c√≥digo.\n",
        "\n",
        "üëâ **Tu objetivo no es recordar cada funci√≥n o par√°metro, sino entender qu√© hace cada bloque**.\n",
        "\n",
        "- ¬øPor qu√© se usa `ReLU` en una capa oculta?\n",
        "- ¬øQu√© significa `categorical_crossentropy` y cu√°ndo se usa?\n",
        "- ¬øPor qu√© usamos `softmax` en la salida para clasificaci√≥n multiclase?\n",
        "\n",
        "Estas preguntas valen m√°s que repetir c√≥digo de memoria.\n",
        "\n",
        "#### üí° Recomendaciones:\n",
        "\n",
        "- Si no recuerdas la sintaxis: **b√∫scala o usa ejemplos anteriores**.\n",
        "- Si ves una funci√≥n nueva: **lee su descripci√≥n** o prueba con `help(funci√≥n)` o `Shift + Tab` en Jupyter.\n",
        "- Si algo no funciona: **imprime variables, revisa formas (`.shape`), ejecuta por partes**.\n",
        "- Si te bloqueas: **comparte lo que est√°s intentando hacer, no solo el error**.\n",
        "\n",
        "**Aprender a programar es como aprender a hablar otro idioma: necesitas pr√°ctica, contexto y repetici√≥n. La memoria vendr√° despu√©s.**"
      ],
      "metadata": {
        "id": "7OO8G-gG9Cy3"
      },
      "id": "7OO8G-gG9Cy3"
    },
    {
      "cell_type": "markdown",
      "id": "4a1b8213",
      "metadata": {
        "id": "4a1b8213"
      },
      "source": [
        "## 1. Carga y Exploraci√≥n de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482b1b60",
      "metadata": {
        "id": "482b1b60"
      },
      "source": [
        "### ¬øQu√© es?\n",
        "\n",
        "Cargar y explorar datos es el primer paso de cualquier proceso de an√°lisis. Aqu√≠ es donde obtenemos una primera impresi√≥n de c√≥mo est√°n estructurados los datos, qu√© tipo de variables tenemos, si hay valores nulos, columnas irrelevantes, etc.\n",
        "\n",
        "Esto se conoce tambi√©n como **ETL (Extract, Transform, Load)** en entornos m√°s profesionales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc50d34",
      "metadata": {
        "id": "2dc50d34"
      },
      "source": [
        "### 1.1 Cargar un archivo CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250cd5a4",
      "metadata": {
        "id": "250cd5a4"
      },
      "source": [
        "**C√≥digo de ejemplo:**  \n",
        "Cargamos un dataset desde un archivo CSV local o una URL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2799c8",
      "metadata": {
        "id": "ae2799c8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar archivo desde local\n",
        "df = pd.read_csv(\"datos_calidad.csv\")  # Carga un archivo CSV en un DataFrame de pandas\n",
        "# Tambi√©n se puede usar una URL si el archivo est√° en l√≠nea\n",
        "# df = pd.read_csv(\"https://ruta-al-archivo/dataset.csv\")\n",
        "\n",
        "df.head()  # Muestra las primeras filas del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbe2c369",
      "metadata": {
        "id": "bbe2c369"
      },
      "source": [
        "**Ejercicio guiado:**  \n",
        "Cambia el nombre del archivo anterior por otro CSV disponible en tu equipo o entorno, y muestra las 10 primeras filas usando `.head(10)`.\n",
        "\n",
        "En Colab, puedes hacer click en la barra lateral izquierda, en el icono \"Archivos\" y subir ah√≠ tus datos desde el PC o desde Drive para que est√©n disponibles en este entorno. Cuando reinicies el entorno desaparecer√°n.\n",
        "\n",
        "Una vez tengas el archivo subido, te recomiendo hacer click derecho > \"Copiar Ruta\". Por ejemplo, tendr√≠as `pd.read_csv(\"/content/sample_data/mnist_train_small.csv\n",
        "\")`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6840d7c5",
      "metadata": {
        "id": "6840d7c5"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Este paso es fundamental para poder trabajar con datos reales. Sin esta carga inicial no es posible iniciar ning√∫n an√°lisis, ni visualizaciones ni modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda4e3ee",
      "metadata": {
        "id": "dda4e3ee"
      },
      "source": [
        "### 1.2 Exploraci√≥n inicial del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c073c728",
      "metadata": {
        "id": "c073c728"
      },
      "outputs": [],
      "source": [
        "# Ver forma del dataset\n",
        "print(\"Dimensiones:\", df.shape)\n",
        "\n",
        "# Tipos de datos\n",
        "print(df.dtypes)\n",
        "\n",
        "# Resumen estad√≠stico\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f438df95",
      "metadata": {
        "id": "f438df95"
      },
      "source": [
        "**Explicaci√≥n:**  \n",
        "- `.shape` nos dice cu√°ntas filas y columnas hay.\n",
        "- `.dtypes` muestra el tipo de cada columna.\n",
        "- `.describe()` da estad√≠sticas b√°sicas como media, desviaci√≥n, m√≠nimo y m√°ximo para columnas num√©ricas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec02247",
      "metadata": {
        "id": "cec02247"
      },
      "source": [
        "### 1.3 Comprobaci√≥n de valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c96bccb",
      "metadata": {
        "id": "8c96bccb"
      },
      "outputs": [],
      "source": [
        "# Comprobar nulos por columna\n",
        "df.isnull().sum().sort_values(ascending=False).head(10) # Nos devuelve las 10 columnas con m√°s valores faltantes del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ecf0c6",
      "metadata": {
        "id": "27ecf0c6"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Muchas funciones y modelos no admiten valores nulos, por lo que es importante identificarlos y decidir si se imputan (rellenan) o se eliminan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dea959d",
      "metadata": {
        "id": "6dea959d"
      },
      "source": [
        "### 1.4 Eliminar columnas irrelevantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b476b88",
      "metadata": {
        "id": "9b476b88"
      },
      "outputs": [],
      "source": [
        "# Supongamos que hay una columna 'ID' que no aporta valor predictivo\n",
        "if 'ID' in df.columns:  # Lista los nombres de las columnas\n",
        "    df = df.drop(columns=['ID'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29752b5a",
      "metadata": {
        "id": "29752b5a"
      },
      "source": [
        "**Ejercicio guiado:**  \n",
        "Busca si tu dataset contiene columnas como identificadores, fechas de carga u observaciones constantes y elim√≠nalas del an√°lisis ya que no aportan capacidad predictiva y pueden inferir errores en tus modelos (relaciones esp√∫reas).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "634a1a56",
      "metadata": {
        "id": "634a1a56"
      },
      "source": [
        "## 2. Preparaci√≥n de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfdadfb4",
      "metadata": {
        "id": "cfdadfb4"
      },
      "source": [
        "Antes de entrenar cualquier modelo, es fundamental preparar los datos correctamente.  \n",
        "Este proceso incluye:\n",
        "\n",
        "- **Escalar y normalizar** los datos num√©ricos\n",
        "- **Codificar** variables categ√≥ricas\n",
        "- Aplicar t√©cnicas de **feature engineering**\n",
        "- Preparar los datos para evitar fugas de informaci√≥n y mejorar la generalizaci√≥n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6394b00e",
      "metadata": {
        "id": "6394b00e"
      },
      "source": [
        "### 2.1 Escalado de variables num√©ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96141985",
      "metadata": {
        "id": "96141985"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Selecci√≥n de columnas num√©ricas\n",
        "num_cols = df.select_dtypes(include='number').columns  # Lista los nombres de las columnas num√©ricas.\n",
        "\n",
        "# Escalado est√°ndar\n",
        "scaler = StandardScaler()  # Escalador para normalizar los datos (media=0, desviaci√≥n=1)\n",
        "df_scaled = df.copy() # Copiamos el DataFrame inicial para no alterarlo\n",
        "df_scaled[num_cols] = scaler.fit_transform(df[num_cols])  # Ajusta el modelo y transforma los datos\n",
        "\n",
        "df_scaled.head()  # Muestra las primeras filas del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fac689a",
      "metadata": {
        "id": "2fac689a"
      },
      "source": [
        "**¬øPor qu√© escalar?**  \n",
        "Muchos modelos (KNN, Regresi√≥n Log√≠stica, Redes Neuronales) son sensibles a la escala de las variables.  \n",
        "El `StandardScaler` transforma cada variable para que tenga media 0 y desviaci√≥n est√°ndar 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39eb68a",
      "metadata": {
        "id": "a39eb68a"
      },
      "source": [
        "### 2.2 Codificaci√≥n de variables categ√≥ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e9aef6",
      "metadata": {
        "id": "a7e9aef6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Suponemos que 'Estado' es la variable objetivo\n",
        "if 'Estado' in df.columns:  # Lista los nombres de las columnas\n",
        "    le = LabelEncoder()  # Codificador para convertir categor√≠as en n√∫meros\n",
        "    df['Estado_cod'] = le.fit_transform(df['Estado'])  # Ajusta el modelo y transforma los datos\n",
        "    print(\"Clases:\", list(le.classes_)) # Comprobamos el resultado con print\n",
        "    df[['Estado', 'Estado_cod']].head()  # Muestra las primeras filas del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad832cd7",
      "metadata": {
        "id": "ad832cd7"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Muchos modelos de machine learning necesitan que las variables categ√≥ricas est√©n en formato num√©rico.  \n",
        "`LabelEncoder` convierte etiquetas como `\"OK\"`, `\"KO\"` en `0`, `1`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd2a304",
      "metadata": {
        "id": "ecd2a304"
      },
      "source": [
        "### 2.3 Ingenier√≠a de caracter√≠sticas (Feature Engineering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5b3ac1",
      "metadata": {
        "id": "7d5b3ac1"
      },
      "outputs": [],
      "source": [
        "# Crear una nueva variable: relaci√≥n entre temperatura y presi√≥n\n",
        "df['Temp_Pres_ratio'] = df['Temperatura'] / df['Presion'] # Creamos una nueva variable en df lamada Temp_Pres_Ratio\n",
        "df[['Temperatura', 'Presion', 'Temp_Pres_ratio']].head()  # Muestra las primeras filas del DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222ae148",
      "metadata": {
        "id": "222ae148"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "A veces, relaciones entre variables aportan m√°s valor predictivo que las variables originales por separado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa988d0",
      "metadata": {
        "id": "1fa988d0"
      },
      "source": [
        "### 2.4 Eliminar columnas constantes o duplicadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610a6119",
      "metadata": {
        "id": "610a6119"
      },
      "outputs": [],
      "source": [
        "# Eliminar columnas con un √∫nico valor\n",
        "for col in df.columns:  # Lista los nombres de las columnas\n",
        "    if df[col].nunique() == 1: # Si la columna tiene 1 solo valor √∫nico\n",
        "        df = df.drop(columns=[col]) # Alteramos df para que no contenga esa columna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e9bbc0",
      "metadata": {
        "id": "b2e9bbc0"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Las columnas que no cambian no aportan informaci√≥n y pueden dificultar el entrenamiento o inflar el tama√±o del modelo innecesariamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ab26d4",
      "metadata": {
        "id": "a9ab26d4"
      },
      "source": [
        "## 3. Modelos Supervisados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0b241d",
      "metadata": {
        "id": "ef0b241d"
      },
      "source": [
        "### 3.1 Regresi√≥n Lineal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698420bf",
      "metadata": {
        "id": "698420bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Simular datos de ejemplo\n",
        "X_simple = df[[\"Temperatura\"]]\n",
        "y_simple = df[\"Presion\"]\n",
        "\n",
        "# Modelo\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(X_simple, y_simple)  # Entrena el modelo con los datos de entrenamiento\n",
        "y_pred_lr = model_lr.predict(X_simple)  # Realiza predicciones sobre los datos de prueba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a9fc9b",
      "metadata": {
        "id": "35a9fc9b"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "La regresi√≥n lineal permite predecir un valor num√©rico continuo.  \n",
        "Es √∫til como modelo de referencia y tambi√©n para interpretar relaciones lineales entre variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35b1560",
      "metadata": {
        "id": "e35b1560"
      },
      "source": [
        "### 3.2 Regresi√≥n Log√≠stica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9246c53a",
      "metadata": {
        "id": "9246c53a"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Asumimos que Estado_cod es binaria (0/1)\n",
        "X_log = df_scaled[num_cols]\n",
        "y_log = df[\"Estado_cod\"]\n",
        "\n",
        "model_log = LogisticRegression(max_iter=1000) # Podemos seleccionar el numero m√°ximo de iteraciones\n",
        "model_log.fit(X_log, y_log)  # Entrena el modelo con los datos\n",
        "y_pred_log = model_log.predict(X_log)  # Realiza predicciones sobre los datos de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2368aa44",
      "metadata": {
        "id": "2368aa44"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Clasifica instancias en dos clases (binaria) de forma simple pero efectiva.  \n",
        "Suele ser el modelo base para comparar con otros m√°s complejos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd57382",
      "metadata": {
        "id": "fdd57382"
      },
      "source": [
        "### 3.3 √Årbol de Decisi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400c383a",
      "metadata": {
        "id": "400c383a"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model_dt = DecisionTreeClassifier(max_depth=4)\n",
        "model_dt.fit(X_train_log, y_train_log)  # Entrena el modelo con los datos de entrenamiento\n",
        "y_pred_dt = model_dt.predict(X_test_log)  # Realiza predicciones sobre los datos de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd3eac7",
      "metadata": {
        "id": "ebd3eac7"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Los √°rboles son f√°ciles de interpretar y permiten entender reglas de decisi√≥n.  \n",
        "Son √∫tiles cuando hay relaciones no lineales entre las variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d78e33ae",
      "metadata": {
        "id": "d78e33ae"
      },
      "source": [
        "### 3.4 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233a72c4",
      "metadata": {
        "id": "233a72c4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_rf.fit(X_train_log, y_train_log)  # Entrena el modelo con los datos de entrenamiento\n",
        "y_pred_rf = model_rf.predict(X_test_log)  # Realiza predicciones sobre los datos de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d685b0a4",
      "metadata": {
        "id": "d685b0a4"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Es un ensemble de √°rboles que mejora la robustez y generalizaci√≥n del modelo.  \n",
        "Muy usado en la industria por su rendimiento y facilidad de uso.\n",
        "\n",
        "Cuando el modelo lo permite, es recomendable fijar `random_state` para que el resultado sea repetible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde069ec",
      "metadata": {
        "id": "cde069ec"
      },
      "source": [
        "### 3.5 K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c7380e",
      "metadata": {
        "id": "81c7380e"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "model_knn.fit(X_train_log, y_train_log)  # Entrena el modelo con los datos de entrenamiento\n",
        "y_pred_knn = model_knn.predict(X_test_log)  # Realiza predicciones sobre los datos de prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5be8d25",
      "metadata": {
        "id": "d5be8d25"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Clasifica en base a los vecinos m√°s cercanos.  \n",
        "Muy intuitivo y efectivo en datasets peque√±os y bien escalados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d2c5c30",
      "metadata": {
        "id": "9d2c5c30"
      },
      "source": [
        "## 4. Modelos No Supervisados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ae3297",
      "metadata": {
        "id": "61ae3297"
      },
      "source": [
        "Los modelos no supervisados aprenden a partir de datos **sin etiquetas**. Se utilizan para:\n",
        "- Explorar la estructura interna de los datos\n",
        "- Agrupar observaciones similares\n",
        "- Reducir la dimensionalidad para visualizaci√≥n o mejora de modelos supervisados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bba2a6c",
      "metadata": {
        "id": "8bba2a6c"
      },
      "source": [
        "### 4.1 K-Means - Agrupamiento no supervisado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f2478d",
      "metadata": {
        "id": "01f2478d"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Aplicar KMeans con 2 grupos\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(X)\n",
        "\n",
        "# Graficar los clusters, en el caso de que X tenga 2 variables.\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='Set2')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "            c='black', s=200, alpha=0.7, marker='X', label='Centroides')\n",
        "plt.title(\"Clusters detectados por K-Means\")\n",
        "plt.xlabel(\"Variable 1\")\n",
        "plt.ylabel(\"Variable 2\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2dc249",
      "metadata": {
        "id": "8e2dc249"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "K-Means permite **agrupar observaciones similares** sin necesidad de etiquetas.  \n",
        "Se usa en segmentaci√≥n de clientes, an√°lisis exploratorio y detecci√≥n de patrones no etiquetados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343d1695",
      "metadata": {
        "id": "343d1695"
      },
      "source": [
        "### 4.1 PCA - An√°lisis de Componentes Principales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737ee445",
      "metadata": {
        "id": "737ee445"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Aplicar PCA para reducir a 2 dimensiones\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_log)  # Ajusta el modelo y transforma los datos\n",
        "\n",
        "# Visualizar resultado\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_log, cmap='coolwarm', alpha=0.7)\n",
        "plt.xlabel(\"Componente 1\")\n",
        "plt.ylabel(\"Componente 2\")\n",
        "plt.title(\"Visualizaci√≥n PCA (2D)\")\n",
        "plt.grid(True)\n",
        "plt.show()  # Muestra el gr√°fico generado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3284e9",
      "metadata": {
        "id": "7a3284e9"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "PCA transforma las variables originales en un nuevo conjunto de variables **no correlacionadas**, que capturan la mayor parte de la varianza.\n",
        "Se usa para visualizaci√≥n, compresi√≥n o preprocesamiento antes de modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d315c7ba",
      "metadata": {
        "id": "d315c7ba"
      },
      "source": [
        "## 5. Evaluaci√≥n de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa1c410b",
      "metadata": {
        "id": "fa1c410b"
      },
      "source": [
        "Evaluar el rendimiento de un modelo es tan importante como entrenarlo.  \n",
        "Dependiendo del tipo de problema (clasificaci√≥n o regresi√≥n), usaremos diferentes m√©tricas:\n",
        "\n",
        "- Clasificaci√≥n: precisi√≥n, recall, F1, matriz de confusi√≥n, ROC, AUC\n",
        "- Regresi√≥n: MAE, MSE, RMSE, R¬≤\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f07e9a8",
      "metadata": {
        "id": "8f07e9a8"
      },
      "source": [
        "### 5.1 Matriz de Confusi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dafff74",
      "metadata": {
        "id": "9dafff74"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # Calcula la matriz de confusi√≥n\n",
        "\n",
        "cm = confusion_matrix(y_test_log, y_pred_rf)  # Calcula la matriz de confusi√≥n\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)  # Calcula la matriz de confusi√≥n\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Matriz de Confusi√≥n\")\n",
        "plt.show()  # Muestra el gr√°fico generado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f721e8",
      "metadata": {
        "id": "25f721e8"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Muestra el n√∫mero de aciertos y errores para cada clase.  \n",
        "Ideal para saber **qu√© clases se confunden entre s√≠**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be835dc8",
      "metadata": {
        "id": "be835dc8"
      },
      "source": [
        "### 5.2 Precisi√≥n, Recall, F1 Score, Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05fad1a1",
      "metadata": {
        "id": "05fad1a1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test_log, y_pred_rf))\n",
        "print(\"Precisi√≥n:\", precision_score(y_test_log, y_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_test_log, y_pred_rf))\n",
        "print(\"F1 Score:\", f1_score(y_test_log, y_pred_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc36c6d",
      "metadata": {
        "id": "6cc36c6d"
      },
      "source": [
        "**¬øCu√°ndo usar cada una?**\n",
        "- `Precisi√≥n`: cu√°ntos de los positivos predichos eran correctos\n",
        "- `Recall`: cu√°ntos de los positivos reales fueron capturados\n",
        "- `F1`: equilibrio entre precisi√≥n y recall\n",
        "- `Accuracy`: proporci√≥n de aciertos totales (menos √∫til si hay clases desbalanceadas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9a280f",
      "metadata": {
        "id": "af9a280f"
      },
      "source": [
        "### 5.3 Curva ROC y AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e7becd",
      "metadata": {
        "id": "b1e7becd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_prob = model_rf.predict_proba(X_test_log)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test_log, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.xlabel(\"Tasa de falsos positivos\")\n",
        "plt.ylabel(\"Tasa de verdaderos positivos\")\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()  # Muestra el gr√°fico generado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780c265c",
      "metadata": {
        "id": "780c265c"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Mide la capacidad del modelo para distinguir entre clases.  \n",
        "Cuanto m√°s se acerque el AUC a 1, mejor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88d98aa3",
      "metadata": {
        "id": "88d98aa3"
      },
      "source": [
        "### 5.4 MAE, MSE, RMSE, R¬≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3103018",
      "metadata": {
        "id": "c3103018"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Usamos el modelo de regresi√≥n lineal de antes\n",
        "mae = mean_absolute_error(y_simple, y_pred_lr)\n",
        "mse = mean_squared_error(y_simple, y_pred_lr)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_simple, y_pred_lr)\n",
        "\n",
        "print(f\"MAE: {mae:.2f}\")\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R¬≤: {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd424e6",
      "metadata": {
        "id": "6fd424e6"
      },
      "source": [
        "**¬øQu√© mide cada m√©trica?**\n",
        "- `MAE`: error absoluto medio\n",
        "- `MSE`: error cuadr√°tico medio (penaliza m√°s errores grandes)\n",
        "- `RMSE`: ra√≠z cuadrada del MSE (en mismas unidades que la variable)\n",
        "- `R¬≤`: porcentaje de variabilidad explicada por el modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "452b71ea",
      "metadata": {
        "id": "452b71ea"
      },
      "source": [
        "## 6. T√©cnicas de Optimizaci√≥n y Regularizaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2479e070",
      "metadata": {
        "id": "2479e070"
      },
      "source": [
        "Estas t√©cnicas ayudan a mejorar el rendimiento y la generalizaci√≥n del modelo, especialmente cuando los datos son complejos o limitados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfedb75b",
      "metadata": {
        "id": "bfedb75b"
      },
      "source": [
        "### 6.1 Regularizaci√≥n L1 y L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93fe5ef",
      "metadata": {
        "id": "b93fe5ef"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# L1 (Lasso)\n",
        "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model_l1.fit(X_train_log, y_train_log)  # Entrena el modelo con los datos de entrenamiento\n",
        "\n",
        "# L2 (Ridge)\n",
        "model_l2 = LogisticRegression(penalty='l2')\n",
        "model_l2.fit(X_train_log, y_train_log)  # Entrena el modelo con los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72fb7664",
      "metadata": {
        "id": "72fb7664"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "- `L1`: fuerza coeficientes a cero (selecci√≥n de variables)\n",
        "- `L2`: reduce la magnitud de los coeficientes (reduce overfitting)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6048e62",
      "metadata": {
        "id": "b6048e62"
      },
      "source": [
        "### 6.2 B√∫squeda de hiperpar√°metros con GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f050f14",
      "metadata": {
        "id": "4f050f14"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV  # B√∫squeda exhaustiva de hiperpar√°metros con validaci√≥n cruzada\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [3, 5, 10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='f1_macro')  # B√∫squeda exhaustiva de hiperpar√°metros con validaci√≥n cruzada\n",
        "grid.fit(X_train_log, y_train_log)\n",
        "\n",
        "print(\"Mejores par√°metros:\", grid.best_params_)\n",
        "print(\"Mejor score F1 Macro:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe99e0a6",
      "metadata": {
        "id": "fe99e0a6"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Permite probar muchas combinaciones de hiperpar√°metros y seleccionar la mejor autom√°ticamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1083a6",
      "metadata": {
        "id": "ae1083a6"
      },
      "source": [
        "### 6.3 RandomizedSearchCV (alternativa r√°pida a GridSearch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4f17c3",
      "metadata": {
        "id": "ac4f17c3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV  # B√∫squeda aleatoria de hiperpar√°metros con validaci√≥n cruzada\n",
        "\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 150),\n",
        "    'max_depth': randint(3, 10)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)  # B√∫squeda aleatoria de hiperpar√°metros con validaci√≥n cruzada\n",
        "random_search.fit(X_train_log, y_train_log)\n",
        "\n",
        "print(\"Mejores par√°metros:\", random_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "993c9dbb",
      "metadata": {
        "id": "993c9dbb"
      },
      "source": [
        "### 6.4 Rebalanceo de clases con SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e47f600",
      "metadata": {
        "id": "9e47f600"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE  # T√©cnica para balancear clases generando ejemplos sint√©ticos\n",
        "from collections import Counter\n",
        "\n",
        "smote = SMOTE(random_state=42)  # T√©cnica para balancear clases generando ejemplos sint√©ticos\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train_log, y_train_log)\n",
        "\n",
        "print(\"Distribuci√≥n original:\", Counter(y_train_log))\n",
        "print(\"Distribuci√≥n balanceada:\", Counter(y_train_sm))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4e1b72",
      "metadata": {
        "id": "fe4e1b72"
      },
      "source": [
        "**¬øPara qu√© sirve?**  \n",
        "Genera muestras sint√©ticas para la clase minoritaria y evita el sobreajuste a la clase mayoritaria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086a07bf",
      "metadata": {
        "id": "086a07bf"
      },
      "source": [
        "## 6. Redes Neuronales: desde MLP hasta LSTM y CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f62ea953",
      "metadata": {
        "id": "f62ea953"
      },
      "source": [
        "Las redes neuronales permiten modelar relaciones no lineales complejas.  \n",
        "En esta secci√≥n las construiremos de forma progresiva:\n",
        "\n",
        "1. Red Neuronal Multicapa b√°sica (MLP)\n",
        "2. MLP m√°s profunda con Dropout y activaci√≥n ReLU\n",
        "3. Red LSTM (para series temporales)\n",
        "4. Red Convolucional (CNN, para datos con estructura espacial)\n",
        "5. Uso de EarlyStopping para evitar overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7051c557",
      "metadata": {
        "id": "7051c557"
      },
      "source": [
        "### 6.1 Red Neuronal Multicapa (MLP) B√°sica"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funciones de activaci√≥n m√°s comunes para MLP\n",
        "\n",
        "**ReLU (`relu`)**  \n",
        "- f(x) = max(0, x)  \n",
        "- Muy usada en capas ocultas  \n",
        "- R√°pida y evita saturaci√≥n\n",
        "\n",
        "**Sigmoid (`sigmoid`)**  \n",
        "- f(x) = 1 / (1 + exp(-x))  \n",
        "- Salida entre 0 y 1  \n",
        "- √ötil en clasificaci√≥n binaria (salida)\n",
        "\n",
        "**Softmax (`softmax`)**  \n",
        "- Devuelve probabilidades que suman 1  \n",
        "- Usada en clasificaci√≥n multiclase (salida)\n",
        "\n",
        "**Lineal (`linear`)**  \n",
        "- f(x) = x  \n",
        "- Se usa en regresi√≥n (salida continua)\n"
      ],
      "metadata": {
        "id": "BG4EuTLk3SBa"
      },
      "id": "BG4EuTLk3SBa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.1 Red Neuronal Multicapa para Regresi√≥n\n"
      ],
      "metadata": {
        "id": "jXpomz9u13Se"
      },
      "id": "jXpomz9u13Se"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funciones de p√©rdida m√°s comunes para regresi√≥n\n",
        "\n",
        "- **`mean_squared_error` (MSE)**  \n",
        "  Penaliza fuertemente los errores grandes. Es la m√°s usada por defecto.  \n",
        "  `model.compile(optimizer='adam', loss='mean_squared_error')`\n",
        "\n",
        "- **`mean_absolute_error` (MAE)**  \n",
        "  M√°s robusta a outliers. Penaliza todos los errores por igual.  \n",
        "  `model.compile(optimizer='adam', loss='mean_absolute_error')`\n",
        "\n",
        "- **`huber_loss`**  \n",
        "  Combina MSE y MAE: usa MSE para errores peque√±os y MAE para errores grandes.  \n",
        "  `model.compile(optimizer='adam', loss='huber_loss')`"
      ],
      "metadata": {
        "id": "NJdAiZFV47vk"
      },
      "id": "NJdAiZFV47vk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bloque muestra c√≥mo usar una red neuronal para predecir valores num√©ricos continuos (por ejemplo: precio, temperatura, producci√≥n, etc.), en lugar de clasificar clases.\n",
        "\n",
        "¬∑ √öltima capa: solo tiene 1 neurona\n",
        "\n",
        "¬∑ Activaci√≥n final: sin activaci√≥n (linear)\n",
        "\n",
        "¬∑ Funci√≥n de p√©rdida: usamos mean_squared_error en lugar de categorical_crossentropy"
      ],
      "metadata": {
        "id": "Kv60OInD2Dsh"
      },
      "id": "Kv60OInD2Dsh"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense  # Capa densamente conectada (fully connected), t√≠pica en MLP\n",
        "\n",
        "# Crear un modelo secuencial: las capas se a√±aden en orden, una tras otra\n",
        "model_reg = Sequential()\n",
        "\n",
        "# Primera capa oculta con 64 neuronas y activaci√≥n ReLU\n",
        "# input_shape define el n√∫mero de variables de entrada\n",
        "model_reg.add(Dense(64, activation='relu', input_shape=(X_train_reg.shape[1],)))\n",
        "\n",
        "# Segunda capa oculta con 32 neuronas y activaci√≥n ReLU\n",
        "model_reg.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Capa de salida con 1 sola neurona (predicci√≥n escalar continua)\n",
        "# No se usa funci√≥n de activaci√≥n ‚Üí salida lineal (ideal para regresi√≥n)\n",
        "model_reg.add(Dense(1))\n",
        "\n",
        "# Compilar el modelo:\n",
        "# - Optimizador: Adam, muy usado por su estabilidad y buen rendimiento\n",
        "# - P√©rdida: mean_squared_error (error cuadr√°tico medio, t√≠pico en regresi√≥n)\n",
        "# - M√©trica: mean_absolute_error para tener una idea clara del error medio en unidades originales\n",
        "model_reg.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Entrenar el modelo:\n",
        "# - validation_split=0.2: reserva el 20% de los datos de entrenamiento para validaci√≥n interna\n",
        "# - epochs=100: n√∫mero de pasadas completas sobre los datos\n",
        "# - batch_size=32: n√∫mero de muestras que se procesan antes de actualizar los pesos\n",
        "# - verbose=0: no muestra el progreso durante el entrenamiento (usa 1 o 2 si se quiere visualizar)\n",
        "history_reg = model_reg.fit(X_train_reg, y_train_reg,\n",
        "                            validation_split=0.2,\n",
        "                            epochs=100,\n",
        "                            batch_size=32,\n",
        "                            verbose=0)\n",
        "\n",
        "print(\"Entrenamiento completado.\")\n"
      ],
      "metadata": {
        "id": "0R7JzOuT2T8S"
      },
      "id": "0R7JzOuT2T8S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.2 Red Neuronal Multicapa para Clasificaci√≥n\n"
      ],
      "metadata": {
        "id": "AEg_8h-o17hB"
      },
      "id": "AEg_8h-o17hB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funciones de p√©rdida m√°s comunes en clasificaci√≥n\n",
        "\n",
        "**`binary_crossentropy`**  \n",
        "- Para clasificaci√≥n binaria (2 clases)  \n",
        "- Calcula el error entre la clase real y la probabilidad predicha  \n",
        "- Recuerda usar la funcion de activaci√≥n `sigmoid` en la capa de salida\n",
        "- `model.compile(optimizer='adam', loss='binary_crossentropy')`\n",
        "\n",
        "**`categorical_crossentropy`**  \n",
        "- Para clasificaci√≥n multiclase con one-hot encoding  \n",
        "- Se usa cuando la salida tiene varias clases y est√° codificada como vector  \n",
        "- `model.compile(optimizer='adam', loss='categorical_crossentropy')`\n",
        "\n",
        "**`sparse_categorical_crossentropy`**  \n",
        "- Igual que `categorical_crossentropy`, pero con etiquetas como enteros en lugar de one-hot  \n",
        "- M√°s c√≥moda si no usas `to_categorical()`  \n",
        "- `model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')`"
      ],
      "metadata": {
        "id": "HtkSMmtY5GHf"
      },
      "id": "HtkSMmtY5GHf"
    },
    {
      "cell_type": "markdown",
      "id": "6bbe6864",
      "metadata": {
        "id": "6bbe6864"
      },
      "source": [
        "**C√≥digo explicado paso a paso:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b871e8",
      "metadata": {
        "id": "53b871e8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense  # Crea una capa densa (fully connected)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Codificamos las etiquetas enteras como vectores one-hot (necesario para usar softmax + categorical_crossentropy)\n",
        "y_train_cat = to_categorical(y_train_log)\n",
        "y_test_cat = to_categorical(y_test_log)\n",
        "\n",
        "# Crear el modelo secuencial: se a√±aden las capas en orden, una tras otra\n",
        "model_basic = Sequential()\n",
        "\n",
        "# Primera (y √∫nica) capa oculta con 16 neuronas y activaci√≥n ReLU\n",
        "# input_shape define el n√∫mero de caracter√≠sticas de entrada\n",
        "model_basic.add(Dense(16, activation='relu', input_shape=(X_train_log.shape[1],)))\n",
        "\n",
        "# Capa de salida con 2 neuronas (porque tenemos 2 clases) y activaci√≥n softmax\n",
        "# Softmax convierte las salidas en probabilidades que suman 1\n",
        "model_basic.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo:\n",
        "# - Optimizador Adam ajusta autom√°ticamente los pesos\n",
        "# - categorical_crossentropy porque usamos one-hot encoding\n",
        "# - M√©trica de evaluaci√≥n: accuracy\n",
        "model_basic.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "# - validation_split=0.2: usa el 20% de los datos para validaci√≥n\n",
        "# - epochs=100: n√∫mero de veces que se recorren todos los datos de entrenamiento\n",
        "# - batch_size=32: n√∫mero de muestras usadas antes de actualizar los pesos\n",
        "# - verbose=0: silencia la salida (puedes usar 1 o 2 para ver el progreso)\n",
        "history_basic = model_basic.fit(X_train_log, y_train_cat,\n",
        "                                validation_split=0.2,\n",
        "                                epochs=100,\n",
        "                                batch_size=32,\n",
        "                                verbose=0)\n",
        "\n",
        "print(\"Entrenamiento terminado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28cf002",
      "metadata": {
        "id": "f28cf002"
      },
      "source": [
        "**¬øQu√© hace este modelo?**\n",
        "\n",
        "- Toma las variables como entrada (X)\n",
        "- Usa una capa con 16 neuronas y activaci√≥n ReLU\n",
        "- Devuelve una predicci√≥n por clase (softmax)\n",
        "\n",
        "Puedes probar aumentando las neuronas o cambiando el optimizador (el mas comun es `adam`) para encontrar el mejor resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfee04fe",
      "metadata": {
        "id": "bfee04fe"
      },
      "source": [
        "### 6.2 MLP profunda con Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "253dd965",
      "metadata": {
        "id": "253dd965"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Crear modelo secuencial (las capas se apilan en orden)\n",
        "model_deep = Sequential()\n",
        "\n",
        "# Primera capa densa con 64 neuronas y activaci√≥n ReLU\n",
        "# input_shape indica el n√∫mero de variables de entrada (caracter√≠sticas)\n",
        "model_deep.add(Dense(64, activation='relu', input_shape=(X_train_log.shape[1],)))\n",
        "\n",
        "# Dropout apaga aleatoriamente el 30% de las neuronas durante el entrenamiento\n",
        "# Esto ayuda a prevenir overfitting (que el modelo memorice demasiado los datos)\n",
        "model_deep.add(Dropout(0.3))\n",
        "\n",
        "# Segunda capa oculta con 32 neuronas y activaci√≥n ReLU\n",
        "model_deep.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Capa de salida con softmax para clasificaci√≥n multiclase\n",
        "# El n√∫mero de neuronas depende del n√∫mero de clases (columnas de y_train_cat)\n",
        "model_deep.add(Dense(y_train_cat.shape[1], activation='softmax'))\n",
        "\n",
        "# Compilar el modelo:\n",
        "# - optimizador: Adam (ajusta los pesos autom√°ticamente)\n",
        "# - funci√≥n de p√©rdida: categorical_crossentropy (clasificaci√≥n multiclase con one-hot)\n",
        "# - m√©trica: accuracy (porcentaje de aciertos)\n",
        "model_deep.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo:\n",
        "# - validation_split: usa el 20% de los datos como validaci√≥n\n",
        "# - epochs: n√∫mero de iteraciones completas sobre el conjunto de datos\n",
        "# - verbose=0: no muestra la salida del entrenamiento (se puede usar 1 o 2 para ver el progreso)\n",
        "history_deep = model_deep.fit(X_train_log, y_train_cat, validation_split=0.2, epochs=50, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc05272",
      "metadata": {
        "id": "fdc05272"
      },
      "source": [
        "**¬øQu√© mejora esta red respecto a la anterior?**\n",
        "\n",
        "- Tiene m√°s capas y m√°s neuronas.\n",
        "- `Dropout` apaga aleatoriamente neuronas durante el entrenamiento (evita que el modelo memorice demasiado).\n",
        "- Es m√°s robusta y generaliza mejor. Reduce el riesgo de overfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d45ad9",
      "metadata": {
        "id": "d3d45ad9"
      },
      "source": [
        "### 6.3 LSTM - Red para Series Temporales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed35c7a",
      "metadata": {
        "id": "bed35c7a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Simulamos datos secuenciales: 100 muestras, cada una con 10 pasos de tiempo y 5 variables por paso\n",
        "X_seq = np.random.rand(100, 10, 5)  # Forma: (n_muestras, pasos_temporales, n_variables)\n",
        "\n",
        "# Etiquetas aleatorias binarias (0 o 1), codificadas como one-hot para clasificaci√≥n binaria\n",
        "y_seq = to_categorical(np.random.randint(0, 2, 100))\n",
        "\n",
        "# Crear modelo secuencial\n",
        "model_lstm = Sequential()  # Modelo lineal: capa tras capa en orden\n",
        "\n",
        "# A√±adir una capa LSTM con 32 neuronas\n",
        "# Esta capa recibe secuencias de 10 pasos con 5 caracter√≠sticas cada uno\n",
        "model_lstm.add(LSTM(32, input_shape=(10, 5)))\n",
        "\n",
        "# Capa de salida con softmax para clasificaci√≥n binaria (2 clases ‚Üí one-hot)\n",
        "model_lstm.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo usando funci√≥n de p√©rdida multiclase\n",
        "model_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo con los datos secuenciales simulados\n",
        "model_lstm.fit(X_seq, y_seq, epochs=10, verbose=0)\n",
        "\n",
        "print(\"Modelo LSTM entrenado para datos secuenciales.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e2d15b",
      "metadata": {
        "id": "65e2d15b"
      },
      "source": [
        "**¬øCu√°ndo usar LSTM?**\n",
        "\n",
        "- Cuando tienes secuencias temporales: sensores en el tiempo, texto, series temporales\n",
        "- El modelo \"recuerda\" estados anteriores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2776a0b",
      "metadata": {
        "id": "b2776a0b"
      },
      "source": [
        "### 6.4 CNN - Red Convolucional para Im√°genes o Datos Espaciales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db01565",
      "metadata": {
        "id": "6db01565"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Simular im√°genes (100 muestras de 28x28 p√≠xeles con 1 canal ‚Üí im√°genes escala de grises)\n",
        "X_img = np.random.rand(100, 28, 28, 1)\n",
        "y_img = to_categorical(np.random.randint(0, 3, 100))  # Crea etiquetas aleatorias en 3 clases (codificadas one-hot)\n",
        "\n",
        "# Crear el modelo secuencial\n",
        "model_cnn = Sequential()  # Modelo secuencial: las capas se a√±aden en orden lineal\n",
        "\n",
        "# Capa convolucional 2D: extrae caracter√≠sticas espaciales (bordes, texturas, etc.)\n",
        "model_cnn.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "# Capa de max pooling: reduce la dimensionalidad espacial manteniendo lo m√°s relevante\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Capa Flatten: convierte la salida 2D anterior en un vector 1D para conectarla a capas densas\n",
        "model_cnn.add(Flatten())\n",
        "\n",
        "# Capa oculta totalmente conectada (fully connected)\n",
        "model_cnn.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Capa de salida con softmax: devuelve una probabilidad para cada una de las 3 clases\n",
        "model_cnn.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo con p√©rdida para clasificaci√≥n multiclase\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo con los datos simulados\n",
        "model_cnn.fit(X_img, y_img, epochs=10, verbose=0)\n",
        "\n",
        "print(\"Modelo CNN entrenado para datos con estructura espacial.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87cc7b36",
      "metadata": {
        "id": "87cc7b36"
      },
      "source": [
        "**¬øPara qu√© sirve?**\n",
        "\n",
        "- Para im√°genes, series espectrales, o cualquier dato con estructura bidimensional\n",
        "- Detecta patrones locales con filtros convolucionales\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6033dc07",
      "metadata": {
        "id": "6033dc07"
      },
      "source": [
        "### 6.5 Uso de EarlyStopping para evitar overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf3fa7b",
      "metadata": {
        "id": "dcf3fa7b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping  # Detiene el entrenamiento si no mejora en validaci√≥n\n",
        "\n",
        "# Crear un callback de EarlyStopping:\n",
        "# - monitor: m√©trica que se vigila (val_loss = p√©rdida en el conjunto de validaci√≥n)\n",
        "# - patience: n¬∫ de √©pocas que se permite sin mejora antes de detener el entrenamiento\n",
        "# - restore_best_weights: restaura los pesos del modelo con mejor rendimiento\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=5,\n",
        "                           restore_best_weights=True)\n",
        "\n",
        "# Definir un modelo secuencial simple con 2 capas ocultas y softmax en salida\n",
        "model_es = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_log.shape[1],)),  # Primera capa oculta\n",
        "    Dense(32, activation='relu'),                                       # Segunda capa oculta\n",
        "    Dense(y_train_cat.shape[1], activation='softmax')                   # Capa de salida (multiclase)\n",
        "])\n",
        "\n",
        "# Compilar el modelo:\n",
        "# - Optimizador: Adam\n",
        "# - P√©rdida: categorical_crossentropy (porque estamos usando codificaci√≥n one-hot)\n",
        "# - M√©trica: accuracy\n",
        "model_es.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo:\n",
        "# - validation_split=0.2: usa el 20% para validaci√≥n interna\n",
        "# - epochs=100: m√°ximo de √©pocas (EarlyStopping puede detener antes)\n",
        "# - batch_size=32: muestras usadas por iteraci√≥n\n",
        "# - callbacks: ejecuta EarlyStopping si no mejora la p√©rdida de validaci√≥n\n",
        "# - verbose=0: no imprime el progreso (usa 1 si quieres ver m√°s)\n",
        "model_es.fit(X_train_log, y_train_cat,\n",
        "             validation_split=0.2,\n",
        "             epochs=100,\n",
        "             batch_size=32,\n",
        "             callbacks=[early_stop],\n",
        "             verbose=0)\n",
        "\n",
        "print(\"Entrenamiento con EarlyStopping finalizado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2674248",
      "metadata": {
        "id": "b2674248"
      },
      "source": [
        "**¬øQu√© hace EarlyStopping?**\n",
        "\n",
        "- Supervisa el rendimiento en validaci√≥n\n",
        "- Si no mejora durante varias √©pocas (`patience`), detiene el entrenamiento\n",
        "- Ahorra tiempo y evita sobreajuste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8ddc3b",
      "metadata": {
        "id": "1d8ddc3b"
      },
      "source": [
        "## 7. Buenas pr√°cticas de programaci√≥n y consejos para aprender Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab5fdda",
      "metadata": {
        "id": "aab5fdda"
      },
      "source": [
        "Aprender a programar y resolver problemas de Machine Learning lleva tiempo. Estos consejos te ayudar√°n a desarrollar buenos h√°bitos desde el inicio y evitar errores comunes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b5a6ba",
      "metadata": {
        "id": "e1b5a6ba"
      },
      "source": [
        "### 7.1 Estructura y claridad en tu c√≥digo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed74d838",
      "metadata": {
        "id": "ed74d838"
      },
      "source": [
        "- Escribe tu c√≥digo en bloques l√≥gicos separados por secciones.\n",
        "- Usa nombres de variables descriptivos (`X_train`, `y_test`, `modelo_rf`, etc).\n",
        "- Deja comentarios claros explicando qu√© hace cada bloque.\n",
        "- Elimina c√≥digo muerto o duplicado que no se est√© usando.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53e4d1f",
      "metadata": {
        "id": "b53e4d1f"
      },
      "source": [
        "### 7.2 Prueba tu c√≥digo por partes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce2f6aa",
      "metadata": {
        "id": "2ce2f6aa"
      },
      "source": [
        "- No intentes resolver todo en una sola celda o paso.\n",
        "- Ejecuta paso a paso: primero carga de datos, luego separaci√≥n, luego modelo...\n",
        "- Si algo falla, imprime los shapes de tus variables y revisa el contenido con `.head()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9bb4934",
      "metadata": {
        "id": "b9bb4934"
      },
      "source": [
        "### 7.3 Aprende a leer documentaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc64ff0c",
      "metadata": {
        "id": "bc64ff0c"
      },
      "source": [
        "- Usa `Shift + Tab` en notebooks o `help(funci√≥n)` para ver qu√© hace un m√©todo.\n",
        "- Lee la documentaci√≥n oficial de Scikit-learn, Pandas, Seaborn y Keras.\n",
        "- Copia ejemplos peque√±os y prueba cambiando par√°metros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f231896f",
      "metadata": {
        "id": "f231896f"
      },
      "source": [
        "### 7.4 Reutiliza tus propios c√≥digos y este manual como plantillas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa2de43",
      "metadata": {
        "id": "5aa2de43"
      },
      "source": [
        "- Guarda notebooks que ya te han funcionado.\n",
        "- Usa una plantilla para cargar datos, otra para entrenar modelos, otra para gr√°ficas.\n",
        "- Esto te permitir√° resolver ejercicios m√°s r√°pido en el futuro y te dar√° confianza.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3313142b",
      "metadata": {
        "id": "3313142b"
      },
      "source": [
        "### 7.5 Ten paciencia y repite lo b√°sico muchas veces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed990b9",
      "metadata": {
        "id": "9ed990b9"
      },
      "source": [
        "- No intentes dominar todos los modelos a la vez.\n",
        "- Domina primero uno (RandomForest o Regresi√≥n Log√≠stica) y eval√∫alo bien.\n",
        "- El aprendizaje real viene de repetir un problema con distintos datasets y estructuras.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}