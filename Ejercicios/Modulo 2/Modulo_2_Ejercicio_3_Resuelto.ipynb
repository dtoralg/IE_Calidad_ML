{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3GSJ7znEZ6lnIwC24W2d+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%202/Modulo_2_Ejercicio_3_Resuelto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3: Integración y Consolidación de Datos\n",
        "\n",
        "## Objetivo\n",
        "En este ejercicio aprenderás a:\n",
        "- Cargar dos datasets online usando Pandas.\n",
        "- Explorar y comparar la estructura de ambos conjuntos de datos.\n",
        "- Verificar la existencia de una clave común (en este caso, `PassengerId`).\n",
        "- Fusionar ambos DataFrames utilizando esa clave para consolidar la información.\n",
        "- Validar la integración mediante pruebas automatizadas.\n",
        "\n",
        "Utilizaremos dos datasets relacionados con el Titanic:\n",
        "\n",
        "1. **Dataset Principal:**  \n",
        "   Información básica de los pasajeros del Titanic.  \n",
        "   **URL:**  \n",
        "   `https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv`\n",
        "\n",
        "2. **Dataset Extra:**  \n",
        "   Información adicional de los pasajeros (por ejemplo, el título extraído del nombre, tamaño de la familia, etc.).  \n",
        "   **URL:**  \n",
        "   `https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic_extra.csv`\n",
        "\n",
        "> **Pregunta de Reflexión:**  \n",
        "> ¿Qué información adicional te gustaría tener para complementar el análisis de los pasajeros? ¿Cómo crees que esto puede ayudar a mejorar un modelo predictivo?\n",
        "\n",
        "¡Comencemos con la integración de datos!\n"
      ],
      "metadata": {
        "id": "FKlIpMvbwBTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIu1zCxsv5ve"
      },
      "outputs": [],
      "source": [
        "# Paso 1: Importa las librerías necesarias y carga ambos datasets.\n",
        "\n",
        "# TODO: Importa pandas y, si lo consideras útil, matplotlib o seaborn para visualizaciones.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define las URLs de ambos datasets\n",
        "url_titanic = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "url_extra   = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic_extra.csv\"\n",
        "\n",
        "# TODO: Carga el dataset principal usando pd.read_csv() y almacénalo en un DataFrame llamado 'df_titanic'\n",
        "df_titanic = pd.read_csv(url_titanic)\n",
        "\n",
        "# TODO: Carga el dataset extra usando pd.read_csv() y almacénalo en un DataFrame llamado 'df_extra'\n",
        "df_extra = pd.read_csv(url_extra)\n",
        "\n",
        "# Visualiza las primeras filas de cada DataFrame para comprobar la carga\n",
        "print(\"Primeras filas del dataset Titanic:\")\n",
        "display(df_titanic.head())\n",
        "\n",
        "print(\"Primeras filas del dataset Extra:\")\n",
        "display(df_extra.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Explora y compara la estructura de ambos datasets\n",
        "\n",
        "# TODO: Muestra la lista de columnas y los tipos de datos para df_titanic y df_extra\n",
        "print(\"Columnas y tipos de datos en df_titanic:\")\n",
        "print(df_titanic.dtypes)\n",
        "\n",
        "print(\"Columnas y tipos de datos en df_extra:\")\n",
        "print(df_extra.dtypes)\n",
        "\n",
        "# Opcional: Usa df.info() para ver información general de cada DataFrame\n",
        "print(\"Información general de df_titanic:\")\n",
        "display(df_titanic.info())\n",
        "\n",
        "print(\"Información general de df_extra:\")\n",
        "display(df_extra.info())\n"
      ],
      "metadata": {
        "id": "PYvCNLWLwFOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Verificar que ambos datasets contienen la clave común 'PassengerId'\n",
        "\n",
        "# Se usará 'PassengerId' como clave para la integración.\n",
        "clave_comun = 'PassengerId'\n",
        "\n",
        "# TODO: Verifica que 'PassengerId' exista en df_titanic y df_extra, e imprime un mensaje confirmándolo.\n",
        "if clave_comun in df_titanic.columns and clave_comun in df_extra.columns:\n",
        "    print(f\"La clave común '{clave_comun}' se encuentra en ambos datasets.\")\n",
        "else:\n",
        "    print(f\"Error: La columna '{clave_comun}' no se encuentra en ambos datasets. Revisa las columnas disponibles.\")\n",
        "\n",
        "# Reflexiona: ¿Qué harías si la clave tuviera nombres distintos en cada dataset?\n"
      ],
      "metadata": {
        "id": "4K9AmzxhwGZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Fusiona los DataFrames utilizando la clave común\n",
        "\n",
        "# TODO: Usa pd.merge() para fusionar df_titanic y df_extra en un nuevo DataFrame llamado 'df_integrado'.\n",
        "# Se recomienda usar un merge de tipo 'inner' para conservar solamente los registros que existen en ambos conjuntos.\n",
        "df_integrado = pd.merge(df_titanic, df_extra, on=clave_comun, how='inner')\n",
        "\n",
        "# Muestra las primeras filas y un resumen del DataFrame integrado para verificar la fusión.\n",
        "print(\"Primeras filas del DataFrame integrado:\")\n",
        "display(df_integrado.head())\n",
        "\n",
        "print(\"Información del DataFrame integrado:\")\n",
        "display(df_integrado.info())\n",
        "\n",
        "# Reflexiona: ¿Qué diferencias notarías si hubieras utilizado un merge 'left'? ¿En qué situaciones podría ser útil?\n"
      ],
      "metadata": {
        "id": "ubimGFKGwHuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6: Sistema de testeo para verificar la integración\n",
        "\n",
        "# Este bloque de código verificará:\n",
        "# 1. Que la fusión se haya realizado sin errores.\n",
        "# 2. Que el número de filas del DataFrame integrado sea el esperado.\n",
        "# 3. Que se haya incorporado al menos una columna del dataset extra (por ejemplo, 'Title').\n",
        "\n",
        "# Supongamos que ambos datasets contienen 891 filas y que el dataset extra tiene una columna llamada 'Title'.\n",
        "expected_rows = 891  # Ajusta este valor si el dataset extra contiene menos registros.\n",
        "column_extra = 'Title'  # Se asume que esta columna está presente en df_extra\n",
        "\n",
        "# Test 1: Verificar número de filas (para un merge 'inner', debería ser igual al número de registros comunes)\n",
        "actual_rows = df_integrado.shape[0]\n",
        "assert actual_rows == expected_rows, f\"Test fallido: Se esperaban {expected_rows} filas, pero se encontraron {actual_rows}.\"\n",
        "\n",
        "# Test 2: Verificar que la columna extra 'Title' esté presente en el DataFrame integrado\n",
        "assert column_extra in df_integrado.columns, f\"Test fallido: La columna '{column_extra}' no se encontró en el DataFrame integrado.\"\n",
        "\n",
        "print(\"Todos los tests se han pasado correctamente. La integración de datos se realizó como se esperaba.\")\n"
      ],
      "metadata": {
        "id": "Cdo2QTMpwJAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflexión Final\n",
        "\n",
        "1. ¿Qué diferencias observaste entre la estructura del dataset principal y el dataset extra?\n",
        "2. ¿Qué información adicional aporta el dataset extra y cómo puede mejorar el análisis o la predicción?\n",
        "3. ¿Qué dificultades encontraste al fusionar ambos conjuntos de datos y cómo las resolviste?\n",
        "4. ¿En qué casos utilizarías un merge 'inner' frente a un merge 'left' o 'outer'?\n",
        "\n",
        "_Responde estas preguntas en una celda Markdown adicional o en un comentario._\n"
      ],
      "metadata": {
        "id": "gxjClIS3wK8R"
      }
    }
  ]
}