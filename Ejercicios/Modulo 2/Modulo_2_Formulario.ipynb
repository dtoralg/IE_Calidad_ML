{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%202/Modulo_2_Formulario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eaeeb84"
      },
      "source": [
        "# Guía General de Técnicas de Preparación y Análisis de Datos\n",
        "\n",
        "Esta guía te ayudará a entender y aplicar las técnicas y comandos esenciales en Python para trabajar con datos. Te insto a tener abierto este formulario mientras trabajas los ejercicios, ya que aquí encontrarás explicado el código que tendrás que utilizar en ellos.\n",
        "\n",
        "Trataremos los siguientes temas de la teoría, desde un enfoque práctico:\n",
        "\n",
        "1. **Importación y Exploración Inicial de Datos**\n",
        "2. **Limpieza de Datos: Duplicados y Valores Faltantes**\n",
        "3. **Detección y Tratamiento de Outliers**\n",
        "4. **Integración y Consolidación de Datos (ETL)**\n",
        "5. **Análisis Exploratorio de Datos (EDA) y Visualización**\n",
        "6. **Transformación y Feature Engineering**\n",
        "\n",
        "Cada sección incluye los comandos y técnicas clave necesarios para abordar el respectivo paso. ¡Vamos a verlo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "376c8d0b"
      },
      "source": [
        "## 1. Importación y Exploración Inicial de Datos\n",
        "\n",
        "**Objetivo:** Cargar datos en un DataFrame y explorar su estructura básica.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Importar Pandas:**\n",
        "  ```python\n",
        "  import pandas as pd\n",
        "  ```\n",
        "- **Cargar un dataset desde CSV o JSON:**\n",
        "  ```python\n",
        "  df = pd.read_csv(\"ruta/del/archivo.csv\")  # O pd.read_json(\"ruta/del/archivo.json\")\n",
        "  ```\n",
        "- **Explorar el DataFrame:**\n",
        "  - `df.head()`: Muestra las primeras filas.\n",
        "  - `df.info()`: Información general (tipos de datos, cantidad de registros).\n",
        "  - `df.describe()`: Estadísticas descriptivas de columnas numéricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c88164ac"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para importar y explorar datos\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar datos (reemplaza la ruta por la de tu archivo)\n",
        "df = pd.read_csv(\"ruta/del/archivo.csv\")\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(df.head())\n",
        "\n",
        "# Información general del DataFrame\n",
        "print(df.info())\n",
        "\n",
        "# Estadísticas descriptivas\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a737ee56"
      },
      "source": [
        "## 2. Limpieza de Datos: Duplicados y Valores Faltantes\n",
        "\n",
        "**Objetivo:** Asegurarse de que los datos sean consistentes y libres de errores.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Detectar duplicados:**\n",
        "  ```python\n",
        "  df.duplicated().sum()\n",
        "  ```\n",
        "- **Eliminar duplicados:**\n",
        "  ```python\n",
        "  df_clean = df.drop_duplicates()\n",
        "  ```\n",
        "- **Detectar valores faltantes:**\n",
        "  ```python\n",
        "  df.isnull().sum()\n",
        "  ```\n",
        "- **Imputar o eliminar valores faltantes:**\n",
        "  ```python\n",
        "  df['columna'] = df['columna'].fillna(df['columna'].median())  # Ejemplo de imputación\n",
        "  df_clean = df.dropna()  # Ejemplo de eliminación\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1e9caca"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para limpieza de datos\n",
        "\n",
        "# Detectar duplicados\n",
        "num_duplicates = df.duplicated().sum()\n",
        "print(\"Número de duplicados:\", num_duplicates)\n",
        "\n",
        "# Eliminar duplicados\n",
        "df_clean = df.drop_duplicates()\n",
        "\n",
        "# Detectar valores nulos\n",
        "print(df_clean.isnull().sum())\n",
        "\n",
        "# Imputar valores nulos con la mediana (ejemplo para una columna genérica)\n",
        "df_clean['columna'] = df_clean['columna'].fillna(df_clean['columna'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a35e61c"
      },
      "source": [
        "## 3. Detección y Tratamiento de Outliers\n",
        "\n",
        "**Objetivo:** Identificar y tratar valores atípicos que puedan distorsionar el análisis.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Visualización con Boxplot:**\n",
        "  ```python\n",
        "  import seaborn as sns\n",
        "  sns.boxplot(x=df['columna'])\n",
        "  ```\n",
        "- **Método del IQR (Rango Intercuartílico):**\n",
        "  ```python\n",
        "  Q1 = df['columna'].quantile(0.25)\n",
        "  Q3 = df['columna'].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df_filtrado = df[(df['columna'] >= Q1 - 1.5 * IQR) & (df['columna'] <= Q3 + 1.5 * IQR)]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0a07a27"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para detectar y tratar outliers\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizar outliers con un boxplot\n",
        "sns.boxplot(x=df_clean['columna'])\n",
        "plt.show()\n",
        "\n",
        "# Aplicar el método del IQR\n",
        "Q1 = df_clean['columna'].quantile(0.25)\n",
        "Q3 = df_clean['columna'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df_filtrado = df_clean[(df_clean['columna'] >= Q1 - 1.5 * IQR) & (df_clean['columna'] <= Q3 + 1.5 * IQR)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f885f87c"
      },
      "source": [
        "## 4. Integración y Consolidación de Datos (ETL)\n",
        "\n",
        "**Objetivo:** Unificar datos provenientes de diferentes fuentes utilizando una clave común.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Fusión de DataFrames con `pd.merge()`:**\n",
        "  ```python\n",
        "  df_integrado = pd.merge(df1, df2, on=\"clave_comun\", how=\"inner\")\n",
        "  ```\n",
        "  - `on`: Especifica la columna clave en ambos DataFrames.\n",
        "  - `how`: Define el tipo de unión (inner, left, right, outer).\n",
        "\n",
        "- **Verificación de la clave:**\n",
        "  ```python\n",
        "  if \"clave_comun\" in df1.columns and \"clave_comun\" in df2.columns:\n",
        "      print(\"La clave existe en ambos DataFrames.\")\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba98c7af"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para la integración de datos\n",
        "\n",
        "# Supongamos que tenemos dos DataFrames: df1 y df2\n",
        "df_integrado = pd.merge(df1, df2, on=\"clave_comun\", how=\"inner\")\n",
        "print(df_integrado.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61511754"
      },
      "source": [
        "## 5. Análisis Exploratorio de Datos (EDA) y Visualización\n",
        "\n",
        "**Objetivo:** Obtener insights mediante el análisis descriptivo y la visualización de los datos.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Estadísticas Descriptivas:**\n",
        "  ```python\n",
        "  df.describe()\n",
        "  df.groupby(\"columna\").describe()\n",
        "  ```\n",
        "- **Visualizaciones:**\n",
        "  - Histograma:\n",
        "    ```python\n",
        "    sns.histplot(df['columna'], kde=True, bins=30)\n",
        "    ```\n",
        "  - Boxplot:\n",
        "    ```python\n",
        "    sns.boxplot(x=df['columna'])\n",
        "    ```\n",
        "  - Scatter Plot:\n",
        "    ```python\n",
        "    sns.scatterplot(x=\"columna1\", y=\"columna2\", data=df, hue=\"columna_categórica\")\n",
        "    ```\n",
        "  - Pairplot:\n",
        "    ```python\n",
        "    sns.pairplot(df, hue=\"columna_categórica\", diag_kind=\"kde\")\n",
        "    ```\n",
        "  - Heatmap (Matriz de Correlación):\n",
        "    ```python\n",
        "    corr = df.corr()\n",
        "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01de95bb"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para análisis exploratorio y visualización\n",
        "\n",
        "print(df.describe())\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Histograma\n",
        "sns.histplot(df['columna'], kde=True, bins=30)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot\n",
        "sns.boxplot(x=df['columna'])\n",
        "plt.show()\n",
        "\n",
        "# Scatter Plot\n",
        "sns.scatterplot(x=\"columna1\", y=\"columna2\", data=df)\n",
        "plt.show()\n",
        "\n",
        "# Pairplot\n",
        "sns.pairplot(df)\n",
        "plt.show()\n",
        "\n",
        "# Heatmap\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0350e8a5"
      },
      "source": [
        "## 6. Transformación y Feature Engineering\n",
        "\n",
        "**Objetivo:** Modificar y crear nuevas variables para enriquecer el análisis y mejorar el desempeño en modelos predictivos.\n",
        "\n",
        "**Técnicas clave:**\n",
        "- **Escalado de Variables Numéricas:**\n",
        "  ```python\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaler = StandardScaler()\n",
        "  df_scaled = pd.DataFrame(scaler.fit_transform(df[numeric_features]), columns=numeric_features)\n",
        "  ```\n",
        "- **Codificación de Variables Categóricas:**\n",
        "  ```python\n",
        "  df_dummies = pd.get_dummies(df[categorical_features], drop_first=True)\n",
        "  ```\n",
        "- **Creación de Nuevas Características:**\n",
        "  ```python\n",
        "  df[\"nueva_feature\"] = df[\"columna1\"] + df[\"columna2\"]  # Ejemplo\n",
        "  ```\n",
        "- **Integración de Variables:**\n",
        "  ```python\n",
        "  df_final = pd.concat([df_scaled, df_dummies, df[[\"nueva_feature\"]]], axis=1)\n",
        "  ```\n",
        "- **(Opcional) Reducción de Dimensionalidad con PCA:**\n",
        "  ```python\n",
        "  from sklearn.decomposition import PCA\n",
        "  pca = PCA(n_components=2)\n",
        "  df_pca = pd.DataFrame(pca.fit_transform(df_final), columns=['PC1', 'PC2'])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3abaf97"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de código para transformación y feature engineering\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Supongamos que numeric_features y categorical_features son listas definidas\n",
        "numeric_features = ['columna1', 'columna2']  # Ejemplo\n",
        "categorical_features = ['columna_cat']\n",
        "\n",
        "# Escalado de variables numéricas\n",
        "scaler = StandardScaler()\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df[numeric_features]), columns=numeric_features)\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "df_dummies = pd.get_dummies(df[categorical_features], drop_first=True)\n",
        "\n",
        "# Creación de una nueva característica\n",
        "df['nueva_feature'] = df['columna1'] + df['columna2']\n",
        "\n",
        "# Integrar variables\n",
        "df_final = pd.concat([df_scaled, df_dummies, df[['nueva_feature']]], axis=1)\n",
        "print(df_final.head())\n",
        "\n",
        "# (Opcional) Reducción de dimensionalidad con PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "df_pca = pd.DataFrame(pca.fit_transform(df_final), columns=['PC1', 'PC2'])\n",
        "print(pca.explained_variance_ratio_)\n",
        "import matplotlib.pyplot as plt\n",
        "sns.scatterplot(x='PC1', y='PC2', data=df_pca)\n",
        "plt.title('Visualización PCA')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc03d0a1"
      },
      "source": [
        "## Conclusión\n",
        "\n",
        "Hemos tratado los conceptos y comandos esenciales para preparar y analizar datos en Python:\n",
        "\n",
        "1. **Importación y Exploración Inicial:** Cómo cargar datos y obtener una visión general.\n",
        "2. **Limpieza de Datos:** Cómo identificar duplicados, manejar valores faltantes y asegurar la calidad de los datos.\n",
        "3. **Detección de Outliers:** Uso de boxplots e IQR para identificar y tratar valores atípicos.\n",
        "4. **Integración de Datos (ETL):** Técnicas para fusionar DataFrames usando una clave común.\n",
        "5. **Análisis Exploratorio (EDA) y Visualización:** Cálculo de estadísticas descriptivas y generación de visualizaciones para identificar patrones y relaciones.\n",
        "6. **Transformación y Feature Engineering:** Escalado, codificación y creación de nuevas variables para enriquecer el análisis y modelado.\n",
        "\n",
        "Utiliza esta guía como referencia para resolver los ejercicios del Módulo 2 y guárdala para tu propia referencia en proyectos futuros de preparación de datos. ¡Buena suerte!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}