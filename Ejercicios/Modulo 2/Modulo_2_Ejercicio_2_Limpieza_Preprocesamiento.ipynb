{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%202/Modulo_2_Ejercicio_2_Limpieza_Preprocesamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3ca264",
      "metadata": {
        "id": "0a3ca264"
      },
      "source": [
        "\n",
        "# **Ejercicio 2: Limpieza y Preprocesamiento de Datos**\n",
        "## Identificación y tratamiento de valores atípicos, duplicados y valores faltantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28362e6",
      "metadata": {
        "id": "c28362e6"
      },
      "source": [
        "\n",
        "## Introducción\n",
        "\n",
        "En este ejercicio, aprenderemos a **limpiar y preprocesar datos** en un dataset industrial.  \n",
        "Los datos del mundo real a menudo contienen valores duplicados, valores atípicos y valores faltantes, los cuales pueden afectar la calidad de los análisis y los modelos predictivos.  \n",
        "\n",
        " **Objetivos del ejercicio:**  \n",
        "- Identificar y eliminar valores duplicados en el dataset.  \n",
        "- Detectar outliers utilizando el **rango intercuartílico (IQR)**.  \n",
        "- Aplicar técnicas de imputación de valores nulos (media, mediana y forward-fill).  \n",
        "- Normalizar y estandarizar variables numéricas para mejorar la comparación de datos.  \n",
        "\n",
        "**Conceptos clave:**  \n",
        "- Detección y eliminación de duplicados  \n",
        "- Manejo de valores nulos  \n",
        "- Normalización y estandarización  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0b08b0",
      "metadata": {
        "id": "da0b08b0"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Importación de librerías necesarias\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuración de estilos para gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "print(\"Librerías importadas correctamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cc7e28",
      "metadata": {
        "id": "52cc7e28"
      },
      "source": [
        "\n",
        "## Descripción del Dataset\n",
        "\n",
        "Para este ejercicio, utilizaremos el dataset **\"Control de calidad en circuitos electrónicos\"**, alojado en GitHub.  \n",
        "Este dataset contiene información sobre circuitos electrónicos y su funcionamiento en condiciones de prueba.\n",
        "\n",
        "📂 **Fuente del dataset:**  \n",
        "[GitHub - Control de calidad en circuitos electrónicos](https://raw.githubusercontent.com/dtoralg/IE_Calidad_ML/refs/heads/main/Data/control_calidad_circuitos_electronicos.csv)\n",
        "\n",
        "### **Estructura del dataset:**\n",
        "| Columna               | Descripción |\n",
        "|-----------------------|-------------|\n",
        "| ID_componente        | Identificador único del componente |\n",
        "| Voltaje_operación    | Voltaje de operación en V |\n",
        "| Corriente_fuga      | Corriente de fuga en mA |\n",
        "| Resistencia_circuito | Resistencia en Ohmios |\n",
        "| Frecuencia_operación | Frecuencia de operación en MHz |\n",
        "| Temperatura_prueba  | Temperatura de prueba en °C |\n",
        "| Horas_operación     | Horas de funcionamiento del circuito |\n",
        "| Proveedor_material  | Nombre del proveedor (categórico) |\n",
        "| Modelo_chip         | Modelo del chip (categórico) |\n",
        "| Método_prueba       | Método de prueba aplicado (categórico) |\n",
        "| Fallo_circuito      | Variable objetivo (OK / KO) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6026de5a",
      "metadata": {
        "id": "6026de5a"
      },
      "outputs": [],
      "source": [
        "# Celda 2: Cargar el dataset desde GitHub\n",
        "\n",
        "url_csv = \"https://raw.githubusercontent.com/dtoralg/IE_Calidad_ML/refs/heads/main/Data/control_calidad_circuitos_electronicos.csv\"\n",
        "...\n",
        "\n",
        "# Mostrar las primeras filas del dataset\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9339ff30",
      "metadata": {
        "id": "9339ff30"
      },
      "outputs": [],
      "source": [
        "# Celda 3: Identificación y eliminación de duplicados\n",
        "print(f\"Número de registros duplicados: {duplicados}\")\n",
        "...\n",
        "\n",
        "# Eliminar duplicados si existen\n",
        "print(\"Duplicados eliminados.\")\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46f1cde",
      "metadata": {
        "id": "a46f1cde"
      },
      "outputs": [],
      "source": [
        "# Celda 4: Detección de valores atípicos (Outliers) usando IQR\n",
        "\n",
        "def detectar_outliers_iqr(data, columna):\n",
        "    Q1 = ...\n",
        "    Q3 = ...\n",
        "    IQR = Q3 - Q1\n",
        "    umbral_inferior = ...\n",
        "    umbral_superior = ...\n",
        "    outliers = ...\n",
        "    return outliers\n",
        "\n",
        "# Detectar outliers en \"Voltaje_operación\"\n",
        "outliers_voltaje = ...\n",
        "print(f\"Valores atípicos en Voltaje_operación: {len(outliers_voltaje)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2793f6f1",
      "metadata": {
        "id": "2793f6f1"
      },
      "outputs": [],
      "source": [
        "# Celda 5: Identificación y manejo de valores nulos\n",
        "\n",
        "print(\"Valores nulos por columna antes de la imputación:\")\n",
        "...\n",
        "\n",
        "# Aplicación de técnicas de imputación\n",
        "...\n",
        "\n",
        "print(\"Valores nulos imputados correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae561693",
      "metadata": {
        "id": "ae561693"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Celda 6: Normalización y estandarización de datos\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Aplicar MinMaxScaler a todas las variables numéricas\n",
        "scaler = ...\n",
        "df[[...]] = scaler.fit_transform(df[[...]])\n",
        "\n",
        "# Aplicar StandardScaler a variables numéricas\n",
        "std_scaler = ...\n",
        "...\n",
        "\n",
        "print(\"Normalización y estandarización aplicadas correctamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5e515b",
      "metadata": {
        "id": "2a5e515b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Celda 7: Visualización de la distribución de los datos\n",
        "\n",
        "# Histograma de la variable Voltaje_operación después de la normalización\n",
        "...\n",
        "\n",
        "# Gráfico de barras para la variable objetivo \"Fallo_circuito\"\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce662b4",
      "metadata": {
        "id": "4ce662b4"
      },
      "source": [
        "\n",
        "## Conclusiones\n",
        "\n",
        "En este ejercicio hemos aplicado distintas técnicas de limpieza y preprocesamiento de datos en un dataset industrial.  \n",
        "\n",
        "\n",
        "**¿Qué podríamos hacer a continuación?**  \n",
        "- Aplicar métodos de eliminación de outliers para mejorar la calidad del dataset.  \n",
        "- Evaluar otras técnicas de imputación de valores nulos, como KNN Imputer.  \n",
        "- Preparar el dataset para un modelo de Machine Learning de clasificación de fallos en circuitos electrónicos.  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}