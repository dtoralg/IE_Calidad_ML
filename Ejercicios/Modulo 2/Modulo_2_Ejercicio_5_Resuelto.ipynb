{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkg/FDHaQ6pHZ3v0LP1U87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%202/Modulo_2_Ejercicio_5_Resuelto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 5: Creación de un Pipeline Avanzado de Machine Learning\n",
        "\n",
        "## Objetivo\n",
        "En este ejercicio, integrarás varios conceptos avanzados:\n",
        "- Cargar y explorar el dataset Wine, disponible en scikit-learn.\n",
        "- Preparar los datos para el modelado (definir variables, dividir en conjuntos de entrenamiento y prueba).\n",
        "- Crear un pipeline que combine un preprocesador (StandardScaler) y un clasificador (por ejemplo, Logistic Regression).\n",
        "- Realizar búsqueda de hiperparámetros mediante GridSearchCV.\n",
        "- Evaluar el rendimiento del modelo mediante validación cruzada y métricas (exactitud y curva ROC).\n",
        "- Visualizar la curva ROC del modelo final.\n",
        "\n",
        "> **Pregunta de Reflexión:**  \n",
        "> ¿Qué ventajas ofrece un pipeline para combinar el preprocesamiento y el modelado?  \n",
        "> ¿Cómo mejora la búsqueda de hiperparámetros (GridSearchCV) el rendimiento del modelo?\n",
        "\n",
        "¡Comencemos!\n"
      ],
      "metadata": {
        "id": "mvW0tPop-sXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Importa las librerías necesarias y carga el dataset Wine.\n",
        "\n",
        "# TODO: Importa pandas, numpy y las librerías de scikit-learn necesarias (datasets, model_selection, pipeline, preprocessing, etc.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "\n",
        "# Carga el dataset Wine usando load_wine con as_frame=True para obtener un DataFrame\n",
        "wine = load_wine(as_frame=True)\n",
        "df_wine = wine.frame\n",
        "\n",
        "# Visualiza las primeras filas del dataset\n",
        "print(\"Primeras filas del dataset Wine:\")\n",
        "display(df_wine.head())\n",
        "\n",
        "# Muestra información general y estadísticas básicas\n",
        "print(\"Información del dataset Wine:\")\n",
        "display(df_wine.info())\n",
        "print(\"Estadísticas descriptivas:\")\n",
        "display(df_wine.describe())\n"
      ],
      "metadata": {
        "id": "Q2Q959R6-sSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Prepara los datos para el modelado.\n",
        "\n",
        "# TODO: Define X (características) e y (etiquetas) a partir del DataFrame.\n",
        "# La etiqueta en el dataset Wine es la columna 'target'.\n",
        "X = df_wine.drop(columns=['target'])\n",
        "y = df_wine['target']\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba (80% / 20%).\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Tamaño de X_train:\", X_train.shape)\n",
        "print(\"Tamaño de X_test:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "ITuY3fPv-wBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Construye un pipeline que integre preprocesamiento y modelado.\n",
        "\n",
        "# TODO: Crea un pipeline que incluya:\n",
        "#  - Una etapa 'scaler' usando StandardScaler.\n",
        "#  - Una etapa 'clf' usando LogisticRegression (puedes usar el solver 'liblinear').\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Define un diccionario de parámetros para la búsqueda de hiperparámetros.\n",
        "# Ejemplo: Ajusta el parámetro 'C' y el tipo de penalización para LogisticRegression.\n",
        "param_grid = {\n",
        "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'clf__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# TODO: Configura y ejecuta GridSearchCV con 5-fold cross validation usando el pipeline.\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejores parámetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Mejor score de validación:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "vwjEdi_Y-xPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Evalúa el modelo en el conjunto de prueba y visualiza la curva ROC.\n",
        "\n",
        "# TODO: Predice las probabilidades en el conjunto de prueba usando grid_search.predict_proba().\n",
        "y_proba = grid_search.predict_proba(X_test)\n",
        "\n",
        "# Calcula la curva ROC.\n",
        "# NOTA: Para la curva ROC en un problema multiclase, se puede elegir la clase 1 (si existe) o usar la estrategia One-vs-Rest.\n",
        "# Aquí usaremos la probabilidad de la clase 1.\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1], pos_label=1)\n",
        "\n",
        "# Calcula el AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Visualiza la curva ROC.\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('Curva ROC del Modelo')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# TODO: Calcula la exactitud del modelo en el conjunto de prueba y muéstrala.\n",
        "y_pred = grid_search.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Exactitud en el conjunto de prueba:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "cUiRyamB-yV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Sistema de testeo para validar el pipeline y la evaluación.\n",
        "\n",
        "# Este bloque de código realizará las siguientes comprobaciones:\n",
        "# 1. Que X_train contenga registros.\n",
        "# 2. Que el pipeline incluya las etapas 'scaler' y 'clf'.\n",
        "# 3. Que se hayan encontrado mejores parámetros (grid_search.best_params_ no sea None).\n",
        "# 4. Que la exactitud en el conjunto de prueba sea superior a 0.7 (valor razonable para este dataset).\n",
        "\n",
        "# Test 1: Verificar que X_train no esté vacío.\n",
        "assert X_train.shape[0] > 0, \"Test fallido: X_train no contiene registros.\"\n",
        "\n",
        "# Test 2: Verificar que el pipeline contenga las etapas 'scaler' y 'clf'.\n",
        "pipeline_steps = [name for name, _ in grid_search.best_estimator_.steps]\n",
        "assert 'scaler' in pipeline_steps, \"Test fallido: La etapa 'scaler' no está en el pipeline.\"\n",
        "assert 'clf' in pipeline_steps, \"Test fallido: La etapa 'clf' no está en el pipeline.\"\n",
        "\n",
        "# Test 3: Verificar que se hayan encontrado mejores parámetros.\n",
        "assert grid_search.best_params_ is not None, \"Test fallido: No se encontraron mejores parámetros.\"\n",
        "\n",
        "# Test 4: Verificar que la exactitud en el conjunto de prueba sea superior a 0.7.\n",
        "assert test_accuracy > 0.7, f\"Test fallido: La exactitud en el conjunto de prueba es demasiado baja ({test_accuracy}).\"\n",
        "\n",
        "print(\"Todos los tests se han pasado correctamente. El pipeline y la evaluación se realizaron como se esperaba.\")\n"
      ],
      "metadata": {
        "id": "MhlHCGJ6-zab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflexión Final\n",
        "\n",
        "1. ¿Qué ventajas encuentras al utilizar un pipeline para integrar preprocesamiento y modelado?\n",
        "2. ¿Cómo contribuye GridSearchCV a la mejora del rendimiento del modelo?\n",
        "3. ¿Qué importancia tiene la visualización de la curva ROC en la evaluación de un modelo de clasificación?\n",
        "4. ¿Podrías proponer otras métricas o técnicas de validación que complementen este análisis?\n",
        "\n",
        "_Responde estas preguntas en una celda Markdown adicional o en un comentario._\n"
      ],
      "metadata": {
        "id": "-6MbAWME-1dn"
      }
    }
  ]
}