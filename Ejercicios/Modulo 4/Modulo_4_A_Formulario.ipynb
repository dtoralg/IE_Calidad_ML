{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%204/Modulo_4_A_Formulario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b12a68",
      "metadata": {
        "id": "36b12a68"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo_4/Modulo_4_Formulario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5457ab97",
      "metadata": {
        "id": "5457ab97"
      },
      "source": [
        "# Guía General de Evaluación de Modelos en Machine Learning\n",
        "\n",
        "Esta guía proporciona una visión general sobre las métricas de evaluación que los alumnos deben conocer para ejecutar correctamente los ejercicios del Módulo 4."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c835582",
      "metadata": {
        "id": "2c835582"
      },
      "source": [
        "## 1. Introducción a las métricas de evaluación\n",
        "\n",
        "Las métricas de evaluación son herramientas fundamentales para medir el rendimiento de un modelo de Machine Learning. Dependiendo del tipo de problema (clasificación o regresión), se utilizan diferentes métricas para determinar si un modelo es adecuado o necesita mejoras.\n",
        "\n",
        "En esta guía veremos cómo calcular e interpretar métricas clave en ambos contextos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8956f46",
      "metadata": {
        "id": "d8956f46"
      },
      "source": [
        "## 2. Métricas de Evaluación para Modelos de Clasificación\n",
        "\n",
        "En problemas de clasificación, queremos medir qué tan bien un modelo predice categorías correctas. Algunas de las métricas más importantes son:\n",
        "\n",
        "- **Matriz de confusión**: Permite visualizar aciertos y errores en la clasificación.\n",
        "- **Precisión (Precision)**: Indica qué proporción de predicciones positivas fueron correctas.\n",
        "- **Recall (Sensibilidad)**: Mide cuántos casos positivos fueron detectados correctamente.\n",
        "- **F1-Score**: Es la media armónica entre precisión y recall, útil en conjuntos desbalanceados.\n",
        "- **Curva ROC y AUC**: Evalúa la capacidad del modelo para distinguir entre clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7d876e",
      "metadata": {
        "id": "1a7d876e"
      },
      "outputs": [],
      "source": [
        "# Ejemplo: Cálculo de la matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Etiquetas reales y predicciones del modelo (Ejemplo)\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
        "y_pred = [1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion = confusion_matrix(y_true, y_pred)\n",
        "print(matriz_confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8690afa9",
      "metadata": {
        "id": "8690afa9"
      },
      "outputs": [],
      "source": [
        "# Cálculo de Precisión, Recall y F1-score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Precisión: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "292874c0",
      "metadata": {
        "id": "292874c0"
      },
      "outputs": [],
      "source": [
        "# Cálculo de Curva ROC y AUC\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Probabilidades predichas (Ejemplo)\n",
        "y_scores = [0.9, 0.2, 0.85, 0.4, 0.3, 0.8, 0.1, 0.6, 0.7, 0.2]\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.xlabel('Falsos Positivos')\n",
        "plt.ylabel('Verdaderos Positivos')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98720bb2",
      "metadata": {
        "id": "98720bb2"
      },
      "source": [
        "## 3. Métricas de Evaluación para Modelos de Regresión\n",
        "\n",
        "En problemas de regresión, evaluamos qué tan cercanas son las predicciones del modelo a los valores reales. Las métricas clave incluyen:\n",
        "\n",
        "- **Error Cuadrático Medio (MSE)**: Penaliza más los errores grandes.\n",
        "- **Raíz del Error Cuadrático Medio (RMSE)**: Permite interpretar el error en la misma escala que la variable objetivo.\n",
        "- **Error Absoluto Medio (MAE)**: Indica la diferencia media entre predicciones y valores reales.\n",
        "- **Coeficiente de Determinación (R²)**: Indica qué proporción de la variabilidad de los datos explica el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fec16f",
      "metadata": {
        "id": "46fec16f"
      },
      "outputs": [],
      "source": [
        "# Cálculo de métricas de regresión\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Valores reales y predicciones (Ejemplo)\n",
        "y_real = np.array([3.0, 2.5, 4.0, 3.8, 5.2])\n",
        "y_pred = np.array([2.8, 2.7, 3.9, 3.6, 5.0])\n",
        "\n",
        "# Calcular métricas\n",
        "mse = mean_squared_error(y_real, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_real, y_pred)\n",
        "r2 = r2_score(y_real, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'R²: {r2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58cf82f7",
      "metadata": {
        "id": "58cf82f7"
      },
      "source": [
        "## 4. Consideraciones Finales\n",
        "\n",
        "- Estas métricas deben interpretarse en el contexto del problema específico.\n",
        "- Para clasificación, es importante evaluar el balance entre precisión y recall.\n",
        "- En regresión, el RMSE y MAE permiten entender mejor el impacto de los errores.\n",
        "- La selección de métricas influye en la optimización de los modelos y en su aplicación en la industria."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}