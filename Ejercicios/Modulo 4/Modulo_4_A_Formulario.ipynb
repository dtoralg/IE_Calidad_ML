{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%204/Modulo_4_A_Formulario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7965abfb",
      "metadata": {
        "id": "7965abfb"
      },
      "source": [
        "# Guía de Evaluación de Modelos en Machine Learning\n",
        "\n",
        "Esta guía proporciona información esencial sobre las métricas de evaluación que se utilizan en los ejercicios del Módulo 4.\n",
        "\n",
        "### Índice\n",
        "1. [Introducción a las Métricas de Evaluación](#section1)\n",
        "2. [Matriz de Confusión](#section2)\n",
        "3. [Precisión, Recall y F1-score](#section3)\n",
        "4. [Curva ROC y AUC](#section4)\n",
        "5. [Métricas para Modelos de Regresión](#section5)\n",
        "6. [Visualización de Resultados](#section6)\n",
        "7. [Consideraciones Finales](#section7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47518fe4",
      "metadata": {
        "id": "47518fe4"
      },
      "source": [
        "## 1. Introducción a las Métricas de Evaluación\n",
        "\n",
        "Las métricas de evaluación permiten medir el rendimiento de un modelo de Machine Learning. Dependiendo del tipo de problema, se utilizan diferentes métricas:\n",
        "\n",
        "- **Clasificación**: Matriz de confusión, precisión, recall, F1-score, curva ROC y AUC.\n",
        "- **Regresión**: Error cuadrático medio (MSE), raíz del error cuadrático medio (RMSE), error absoluto medio (MAE) y coeficiente de determinación (R²)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36e1d90",
      "metadata": {
        "id": "f36e1d90"
      },
      "source": [
        "## 2. Matriz de Confusión\n",
        "\n",
        "La matriz de confusión muestra la cantidad de aciertos y errores en una clasificación binaria o multiclase.\n",
        "\n",
        "**Ejemplo de código para calcular la matriz de confusión:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4dc275",
      "metadata": {
        "id": "de4dc275"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Datos de ejemplo\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
        "y_pred = [1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "matriz_confusion = confusion_matrix(y_true, y_pred)\n",
        "print(matriz_confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f24492f",
      "metadata": {
        "id": "0f24492f"
      },
      "source": [
        "## 3. Precisión, Recall y F1-score\n",
        "\n",
        "- **Precisión**: Indica qué proporción de las predicciones positivas fueron correctas.\n",
        "- **Recall**: Mide cuántos casos positivos fueron detectados correctamente.\n",
        "- **F1-score**: Media armónica entre precisión y recall, útil en datasets desbalanceados.\n",
        "\n",
        "**Ejemplo de código para calcular estas métricas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6bc5a76",
      "metadata": {
        "id": "d6bc5a76"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calcular métricas\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Precisión: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5a67ba",
      "metadata": {
        "id": "6c5a67ba"
      },
      "source": [
        "## 4. Curva ROC y AUC\n",
        "\n",
        "La curva ROC evalúa la capacidad del modelo para distinguir entre clases.\n",
        "\n",
        "**Ejemplo de código para generar la curva ROC:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd77050d",
      "metadata": {
        "id": "dd77050d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Probabilidades predichas (Ejemplo)\n",
        "y_scores = [0.9, 0.2, 0.85, 0.4, 0.3, 0.8, 0.1, 0.6, 0.7, 0.2]\n",
        "\n",
        "# Calcular la curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Graficar la curva ROC\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.xlabel('Falsos Positivos')\n",
        "plt.ylabel('Verdaderos Positivos')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d0de4e",
      "metadata": {
        "id": "93d0de4e"
      },
      "source": [
        "## 5. Métricas para Modelos de Regresión\n",
        "\n",
        "Para modelos de regresión, las métricas más comunes incluyen:\n",
        "- **MSE**: Penaliza más los errores grandes.\n",
        "- **RMSE**: Permite interpretar el error en la misma escala de la variable objetivo.\n",
        "- **MAE**: Indica la diferencia media entre predicciones y valores reales.\n",
        "- **R²**: Indica qué proporción de la variabilidad de los datos explica el modelo.\n",
        "\n",
        "**Ejemplo de código para calcular métricas de regresión:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72de17a",
      "metadata": {
        "id": "a72de17a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Datos de ejemplo\n",
        "y_real = np.array([3.0, 2.5, 4.0, 3.8, 5.2])\n",
        "y_pred = np.array([2.8, 2.7, 3.9, 3.6, 5.0])\n",
        "\n",
        "# Calcular métricas\n",
        "mse = mean_squared_error(y_real, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_real, y_pred)\n",
        "r2 = r2_score(y_real, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'R²: {r2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b646c52b",
      "metadata": {
        "id": "b646c52b"
      },
      "source": [
        "## 6. Consideraciones Finales\n",
        "\n",
        "- Cada métrica es útil en distintos contextos.\n",
        "- Para clasificación, es importante evaluar el balance entre precisión y recall.\n",
        "- En regresión, el RMSE y MAE permiten entender mejor el impacto de los errores.\n",
        "- La selección de métricas influye en la optimización de los modelos y en su aplicación en la industria."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}