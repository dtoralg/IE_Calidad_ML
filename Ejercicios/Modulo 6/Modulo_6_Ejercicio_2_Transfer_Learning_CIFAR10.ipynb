{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%206/Modulo_6_Ejercicio_2_Transfer_Learning_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6676eb5",
      "metadata": {
        "id": "b6676eb5"
      },
      "source": [
        "**Ejercicio 2: Transfer Learning en Defectos Visuales de Producción con CIFAR-10**\n",
        "\n",
        "*Aplicar técnicas de transferencia de aprendizaje usando modelos preentrenados (como MobileNetV2) para clasificar imágenes industriales.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8807cab1",
      "metadata": {
        "id": "8807cab1"
      },
      "source": [
        "En este ejercicio aplicaremos una red neuronal convolucional preentrenada sobre el dataset CIFAR-10 para resolver una tarea de clasificación de imágenes.\n",
        "Primero construiremos una CNN básica como baseline, y luego aplicaremos Transfer Learning usando MobileNetV2.\n",
        "Evaluaremos el rendimiento con métricas de clasificación, curva de pérdida y matriz de confusión."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ### Recomendación:\n",
        "> Las redes neuronales hacen millones de operaciones matemáticas (multiplicaciones de matrices, derivadas, etc.) durante el entrenamiento. Una CPU puede hacer estas operaciones, pero una GPU está diseñada específicamente para hacerlas en paralelo y mucho más rápido.\n",
        ">\n",
        "> Por ello te recomiendo que para estos ejercicios cambies tu entorno de ejecución en Colab.\n",
        ">\n",
        "> Puedes hacerlo haciendo click en `Entorno de Ejecución` en la barra superior, después `Cambiar tipo de entorno de ejecución` y selecciona `GPU`. Esto hará que tus notebook ejecuten más rápido los cálculos con Deep Learning.\n"
      ],
      "metadata": {
        "id": "IGRED2m4WZfN"
      },
      "id": "IGRED2m4WZfN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4b6d61",
      "metadata": {
        "id": "4e4b6d61"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee70fea",
      "metadata": {
        "id": "9ee70fea"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "# Seleccionar solo dos clases para simplificar (por ejemplo: avión y automóvil)\n",
        "selected_classes = [0, 1]  # airplane vs automobile\n",
        "train_mask = np.isin(y_train, selected_classes).flatten()\n",
        "test_mask = np.isin(y_test, selected_classes).flatten()\n",
        "\n",
        "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
        "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
        "y_train = (y_train == selected_classes[1]).astype(int).flatten()\n",
        "y_test = (y_test == selected_classes[1]).astype(int).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8367d4",
      "metadata": {
        "id": "5c8367d4"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento para MobileNetV2\n",
        "# Usa la funcion preprocess_input para formatear la imagen a tamaño 96x96px\n",
        "X_train_prep = ...\n",
        "X_test_prep = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61f88c5",
      "metadata": {
        "id": "c61f88c5"
      },
      "outputs": [],
      "source": [
        "# Crea tu modelo. Te propongo que uses redes Conv2D, seguidas de MaxPooling2D,\n",
        "# Si quieres hacer el modelo más completo, puedes usar Flatten y redes Dense.\n",
        "\n",
        "model = Sequential([\n",
        "...\n",
        "])\n",
        "model.compile(optimizer='...', loss=..., metrics=['...'])\n",
        "model.fit(X_train, y_train, epochs=..., validation_split=..., batch_size=...)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predecimos e incluimos el umbral de clasificacion\n",
        "y_pred = (model.predict(X_test) > ...).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "print(...)\n",
        "\n",
        "# Confusion Matrix\n",
        "print(...)"
      ],
      "metadata": {
        "id": "xdg9Vsge1od7"
      },
      "id": "xdg9Vsge1od7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d3ad8e",
      "metadata": {
        "id": "36d3ad8e"
      },
      "outputs": [],
      "source": [
        "# Iniciamos MobileNetV2 adecuandolo a las imagenes 96x96 que tenemos.\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "\n",
        "# No queremos re-entrenar el modelo con nuestros datos.\n",
        "base_model.trainable = False\n",
        "\n",
        "transfer_model = Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    Dense(..., activation='relu'),\n",
        "    Dropout(...),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "transfer_model.fit(X_train_prep, y_train, epochs=..., validation_split=..., batch_size=...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da2a55f",
      "metadata": {
        "id": "6da2a55f"
      },
      "outputs": [],
      "source": [
        "# Definimos umbral, classification_report y confusion_matrix\n",
        "y_pred = (transfer_model.predict(X_test_prep) > ...).astype(int)\n",
        "print(...)\n",
        "print(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a83d7e5",
      "metadata": {
        "id": "4a83d7e5"
      },
      "source": [
        "**Conclusiones:**\n",
        "\n",
        "- El modelo preentrenado MobileNetV2 ha logrado buenos resultados con pocas épocas de entrenamiento.\n",
        "- Comparado con la CNN básica, ofrece mayor generalización y menor overfitting.\n",
        "- La transferencia de aprendizaje permite aprovechar conocimiento previo incluso en datasets pequeños."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247f6668",
      "metadata": {
        "id": "247f6668"
      },
      "source": [
        "**Próximos pasos:**\n",
        "- Afinar los hiperparámetros y usar `model_checkpoint` y `early_stopping`.\n",
        "- Descongelar capas del modelo base para realizar fine-tuning.\n",
        "- Aplicar técnicas de aumento de datos para mejorar la robustez del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}