{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%206/Modulo_6_Ejercicio_4_Bagging_vs_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3487b8ad",
      "metadata": {
        "id": "3487b8ad"
      },
      "source": [
        "# **Ejercicio 4: Bagging vs Boosting — Comparativa con Datos Ruidosos**\n",
        "**Propósito**: Evaluar la robustez de modelos ensemble (Random Forest vs XGBoost) ante la presencia de ruido en datos industriales reales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "605cd680",
      "metadata": {
        "id": "605cd680"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En este ejercicio evaluaremos la **robustez de técnicas de ensamblado (ensemble)** en presencia de datos ruidosos utilizando un dataset real del entorno de fabricación industrial. Compararemos dos enfoques:\n",
        "\n",
        "- **Bagging** mediante `RandomForestClassifier`.\n",
        "- **Boosting** mediante `XGBClassifier`.\n",
        "\n",
        "Trabajaremos con el **SECOM Manufacturing Data Set**, que contiene mediciones de sensores con alta correlación espuria y ruido inherente.\n",
        "\n",
        "Objetivos principales:\n",
        "\n",
        "- Introducir **ruido artificial** y comparar el rendimiento de los modelos con y sin ruido.\n",
        "- Evaluar métricas clave: **F1 Macro** y **recall por clase**.\n",
        "- Discutir resultados en términos de **robustez** y **bias-variance tradeoff**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e451077",
      "metadata": {
        "id": "3e451077"
      },
      "source": [
        "## Carga de librerías y configuración del entorno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f54c6d",
      "metadata": {
        "id": "a3f54c6d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Estilo gráfico\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción del dataset: SECOM Manufacturing Data Set"
      ],
      "metadata": {
        "id": "L4wPIKpGazD9"
      },
      "id": "L4wPIKpGazD9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fuente**: UCI Machine Learning Repository  \n",
        "https://archive.ics.uci.edu/ml/datasets/SECOM\n",
        "\n",
        "Este conjunto de datos fue recogido en un entorno real de fabricación de semiconductores y contiene:\n",
        "- 1567 observaciones.\n",
        "- 590 variables medidas por sensores.\n",
        "- 1 variable objetivo binaria: `1` (producto defectuoso) / `-1` (producto correcto)."
      ],
      "metadata": {
        "id": "EMUuJAA5axwM"
      },
      "id": "EMUuJAA5axwM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Licencia del dataset:** SECOM Manufacturing Data Set — Fuente: UCI ML Repository, Licencia: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)"
      ],
      "metadata": {
        "id": "fnpd2IYsW_CR"
      },
      "id": "fnpd2IYsW_CR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga y preparación de datos"
      ],
      "metadata": {
        "id": "6n5LESqGa3uI"
      },
      "id": "6n5LESqGa3uI"
    },
    {
      "cell_type": "code",
      "source": [
        "zip_url = \"https://github.com/dtoralg/IE_Calidad_ML/raw/refs/heads/main/Data/Modulo%206/secom.zip\"\n",
        "\n",
        "# Descargar el zip\n",
        "response = requests.get(zip_url)\n",
        "\n",
        "# Verificar que la descarga fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Leer el archivo ZIP en memoria\n",
        "    zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "    # Mostrar el contenido del ZIP\n",
        "    print(\"Archivos contenidos:\")\n",
        "    print(zip_file.namelist())\n",
        "\n",
        "    # Extraer todos los archivos (opcional)\n",
        "    zip_file.extractall(\"secom_data\")  # Carpeta donde se guardarán\n",
        "    print(\"Archivos extraídos en la carpeta 'secom_data'.\")\n",
        "else:\n",
        "    print(\"Error al descargar el archivo:\", response.status_code)"
      ],
      "metadata": {
        "id": "1M_1863_a1sS"
      },
      "id": "1M_1863_a1sS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos desde archivos locales\n",
        "data_path = '/content/secom_data/secom.data'\n",
        "labels_path = '/content/secom_data/secom_labels.data'\n",
        "\n",
        "features_df = pd.read_csv(data_path, sep='\\s+', header=None)\n",
        "labels_df = pd.read_csv(labels_path, sep='\\s+', header=None, names=[\"label\", \"timestamp\"])\n",
        "\n",
        "# Fusionar y preparar dataset\n",
        "df = pd.concat([features_df, labels_df[\"label\"]], axis=1)\n",
        "df.dropna(axis=1, thresh=800, inplace=True)  # columnas con demasiados NaNs\n",
        "df.fillna(df.median(numeric_only=True), inplace=True)  # imputación\n",
        "\n",
        "# Separar variables y objetivo\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = ... # Selecciona 'label' y conviertela en binaria\n",
        "\n",
        "# Escalar\n",
        "scaler = ...\n",
        "X_scaled = ...\n",
        "\n",
        "# Dividir\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "print(\"Distribución de clases en train:\", y_train.value_counts().to_dict())"
      ],
      "metadata": {
        "id": "Z027cEQsa-Th"
      },
      "id": "Z027cEQsa-Th",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "55bbd010",
      "metadata": {
        "id": "55bbd010"
      },
      "source": [
        "## Estrategias para tratar el desbalanceo de clases"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3d278e",
      "metadata": {
        "id": "6f3d278e"
      },
      "source": [
        "La clase `1` (productos defectuosos) representa una proporción muy pequeña del dataset.  \n",
        "Para mejorar el rendimiento del modelo en esta clase minoritaria, aplicaremos técnicas de balanceo:\n",
        "\n",
        "- **SMOTE (Synthetic Minority Over-sampling Technique)**: genera ejemplos sintéticos de la clase minoritaria.\n",
        "- **Ajuste de pesos en los modelos**: se le da mayor peso a la clase minoritaria para penalizar más sus errores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629226c6",
      "metadata": {
        "id": "629226c6"
      },
      "outputs": [],
      "source": [
        "# Aplicar SMOTE solo sobre el conjunto de entrenamiento\n",
        "smote = ...\n",
        "X_train_balanced, y_train_balanced = ...\n",
        "\n",
        "# También aplicamos ruido al conjunto balanceado para identificar que modelo se comporta mejor\n",
        "np.random.seed(42)\n",
        "noise_bal = np.random.normal(loc=0, scale=0.5, size=X_train_balanced.shape)\n",
        "X_train_balanced_noisy = X_train_balanced + noise_bal\n",
        "\n",
        "# Mostrar nueva distribución\n",
        "print(\"Distribución tras SMOTE:\", pd.Series(y_train_balanced).value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e22b6c5",
      "metadata": {
        "id": "0e22b6c5"
      },
      "source": [
        "## Reentrenamiento con datos balanceados (SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b999ab2a",
      "metadata": {
        "id": "b999ab2a"
      },
      "outputs": [],
      "source": [
        "# Random Forest con SMOTE\n",
        "rf_smote = ...\n",
        "rf_smote.fit(...)\n",
        "y_pred_rf_smote = rf_smote.predict(...)\n",
        "\n",
        "# XGBoost con SMOTE\n",
        "xgb_smote = XGBClassifier(...)\n",
        "xgb_smote.fit(...)\n",
        "y_pred_xgb_smote = xgb_smote.predict(...)\n",
        "\n",
        "# Métricas\n",
        "f1_rf_smote = f1_score(y_test, y_pred_rf_smote, average='macro')\n",
        "f1_xgb_smote = f1_score(y_test, y_pred_xgb_smote, average='macro')\n",
        "recall_rf_smote = recall_score(y_test, y_pred_rf_smote, average=None)\n",
        "recall_xgb_smote = recall_score(y_test, y_pred_xgb_smote, average=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450d6b4c",
      "metadata": {
        "id": "450d6b4c"
      },
      "outputs": [],
      "source": [
        "# Random Forest con SMOTE + ruido\n",
        "rf_smote_noisy = RandomForestClassifier(...)\n",
        "rf_smote_noisy.fit(...)\n",
        "y_pred_rf_smote_noisy = rf_smote_noisy.predict(...)\n",
        "\n",
        "# XGBoost con SMOTE + ruido\n",
        "xgb_smote_noisy = XGBClassifier(...)\n",
        "xgb_smote_noisy.fit(...)\n",
        "y_pred_xgb_smote_noisy = xgb_smote_noisy.predict(...)\n",
        "\n",
        "# Métricas\n",
        "f1_rf_smote_noisy = f1_score(y_test, y_pred_rf_smote_noisy, average='macro')\n",
        "f1_xgb_smote_noisy = f1_score(y_test, y_pred_xgb_smote_noisy, average='macro')\n",
        "recall_rf_smote_noisy = recall_score(y_test, y_pred_rf_smote_noisy, average=None)\n",
        "recall_xgb_smote_noisy = recall_score(y_test, y_pred_xgb_smote_noisy, average=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a94d5389",
      "metadata": {
        "id": "a94d5389"
      },
      "source": [
        "## Comparación de resultados con técnicas de balanceo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ba014f",
      "metadata": {
        "id": "86ba014f"
      },
      "outputs": [],
      "source": [
        "# Añadir nuevos resultados\n",
        "results_df_bal = pd.DataFrame({\n",
        "    \"Modelo\": [\n",
        "        \"Random Forest (SMOTE)\", \"XGBoost (SMOTE)\",\n",
        "        \"Random Forest (SMOTE + Ruido)\", \"XGBoost (SMOTE + Ruido)\"\n",
        "    ],\n",
        "    \"F1 Macro\": [f1_rf_smote, f1_xgb_smote, f1_rf_smote_noisy, f1_xgb_smote_noisy],\n",
        "    \"Recall Clase 0\": [recall_rf_smote[0], recall_xgb_smote[0], recall_rf_smote_noisy[0], recall_xgb_smote_noisy[0]],\n",
        "    \"Recall Clase 1\": [recall_rf_smote[1], recall_xgb_smote[1], recall_rf_smote_noisy[1], recall_xgb_smote_noisy[1]]\n",
        "})\n",
        "\n",
        "\n",
        "results_df_bal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599b1d43",
      "metadata": {
        "id": "599b1d43"
      },
      "source": [
        "## Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11437bf7",
      "metadata": {
        "id": "11437bf7"
      },
      "source": [
        "- **XGBoost** muestra mayor robustez ante ruido.\n",
        "- **XGBoost** tiene mejor F1 sin ruido y consigue generalizar bien al introducirlo, en una medida similar a RandomForest\n",
        "- El **recall para la clase minoritaria** mejora considerablemente con Boosting + ruido. Esto se debe a que el modelo original tiende a sobreajustarse, aun con el uso de SMOTE, y con el ruido introducido pierde capacidad predictiva de la clase 0 en favor de la clase 1 (generaliza mejor)\n",
        "\n",
        "Este ejercicio demuestra el **trade-off entre bias y varianza**:\n",
        "- Bagging reduce varianza, es más robusto.\n",
        "- Boosting reduce sesgo, pero es más sensible al ruido."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2af4c32f",
      "metadata": {
        "id": "2af4c32f"
      },
      "source": [
        "## Próximos pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c300e6ad",
      "metadata": {
        "id": "c300e6ad"
      },
      "source": [
        "- Ajustar hiperparámetros para cada modelo.\n",
        "- Aplicar técnicas de selección de características para reducir dimensionalidad.\n",
        "- Explorar otras técnicas de ensemble como Stacking.\n",
        "\n",
        "---\n",
        "\n",
        "Dataset original: SECOM Manufacturing Data Set — UCI Machine Learning Repository\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}