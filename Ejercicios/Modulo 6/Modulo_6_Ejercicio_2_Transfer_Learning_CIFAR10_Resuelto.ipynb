{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%206/Modulo_6_Ejercicio_2_Transfer_Learning_CIFAR10_Resuelto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6676eb5",
      "metadata": {
        "id": "b6676eb5"
      },
      "source": [
        "**Ejercicio 2: Transfer Learning en Defectos Visuales de Producción con CIFAR-10**\n",
        "\n",
        "*Aplicar técnicas de transferencia de aprendizaje usando modelos preentrenados (como MobileNetV2) para clasificar imágenes industriales.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8807cab1",
      "metadata": {
        "id": "8807cab1"
      },
      "source": [
        "En este ejercicio aplicaremos una red neuronal convolucional preentrenada sobre el dataset CIFAR-10 para resolver una tarea de clasificación de imágenes.\n",
        "Primero construiremos una CNN básica como baseline, y luego aplicaremos Transfer Learning usando MobileNetV2.\n",
        "Evaluaremos el rendimiento con métricas de clasificación, curva de pérdida y matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e4b6d61",
      "metadata": {
        "id": "4e4b6d61"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ee70fea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ee70fea",
        "outputId": "85ec19c1-dfa0-44fc-d8fa-a9ab0c720181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "# Seleccionar solo dos clases para simplificar (por ejemplo: avión y automóvil)\n",
        "selected_classes = [0, 1]  # airplane vs automobile\n",
        "train_mask = np.isin(y_train, selected_classes).flatten()\n",
        "test_mask = np.isin(y_test, selected_classes).flatten()\n",
        "\n",
        "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
        "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
        "y_train = (y_train == selected_classes[1]).astype(int).flatten()\n",
        "y_test = (y_test == selected_classes[1]).astype(int).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c8367d4",
      "metadata": {
        "id": "5c8367d4"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento para MobileNetV2\n",
        "X_train_prep = preprocess_input(tf.image.resize(X_train, [96, 96]))\n",
        "X_test_prep = preprocess_input(tf.image.resize(X_test, [96, 96]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c61f88c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61f88c5",
        "outputId": "d7c8d319-4265-42c9-a0c0-013ae71e6bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6102 - loss: 8.6299 - val_accuracy: 0.8170 - val_loss: 0.4268\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.4059 - val_accuracy: 0.8715 - val_loss: 0.2926\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.3336 - val_accuracy: 0.8870 - val_loss: 0.2703\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8858 - loss: 0.2824 - val_accuracy: 0.8955 - val_loss: 0.2442\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.2528 - val_accuracy: 0.9140 - val_loss: 0.2188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c90f6264c90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdg9Vsge1od7",
        "outputId": "2bcac9ba-1d2a-41a3-d278-b4d8a95d3d64"
      },
      "id": "xdg9Vsge1od7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      1000\n",
            "           1       0.93      0.94      0.93      1000\n",
            "\n",
            "    accuracy                           0.93      2000\n",
            "   macro avg       0.93      0.93      0.93      2000\n",
            "weighted avg       0.93      0.93      0.93      2000\n",
            "\n",
            "[[928  72]\n",
            " [ 65 935]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "36d3ad8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36d3ad8e",
        "outputId": "e6d0a860-f1c6-43b1-ab59-cb3b20563d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - accuracy: 0.9326 - loss: 0.1717 - val_accuracy: 0.9835 - val_loss: 0.0463\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9827 - loss: 0.0467 - val_accuracy: 0.9850 - val_loss: 0.0454\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9876 - loss: 0.0366 - val_accuracy: 0.9835 - val_loss: 0.0451\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9886 - loss: 0.0300 - val_accuracy: 0.9840 - val_loss: 0.0492\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9919 - loss: 0.0240 - val_accuracy: 0.9860 - val_loss: 0.0411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c90e03eab50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "transfer_model = Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "transfer_model.fit(X_train_prep, y_train, epochs=5, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6da2a55f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6da2a55f",
        "outputId": "56dfd0ca-2aa3-4fcc-cc59-5e10b0879fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "\n",
            "    accuracy                           0.99      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       0.99      0.99      0.99      2000\n",
            "\n",
            "[[985  15]\n",
            " [ 12 988]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = (transfer_model.predict(X_test_prep) > 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a83d7e5",
      "metadata": {
        "id": "4a83d7e5"
      },
      "source": [
        "**Conclusiones:**\n",
        "\n",
        "- El modelo preentrenado MobileNetV2 ha logrado buenos resultados con pocas épocas de entrenamiento.\n",
        "- Comparado con la CNN básica, ofrece mayor generalización y menor overfitting.\n",
        "- La transferencia de aprendizaje permite aprovechar conocimiento previo incluso en datasets pequeños."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247f6668",
      "metadata": {
        "id": "247f6668"
      },
      "source": [
        "**Próximos pasos:**\n",
        "- Afinar los hiperparámetros y usar `model_checkpoint` y `early_stopping`.\n",
        "- Descongelar capas del modelo base para realizar fine-tuning.\n",
        "- Aplicar técnicas de aumento de datos para mejorar la robustez del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}