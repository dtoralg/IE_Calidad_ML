{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%205/Modulo_5_Ejercicio_1_Sobreajuste_Arboles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c11b01",
      "metadata": {
        "id": "e4c11b01"
      },
      "source": [
        "### **Ejercicio 1: ¿Cuándo un modelo se está sobreajustando? Visualízalo tú mismo**\n",
        "**Diagnóstico visual del sobreajuste ajustando la profundidad de un árbol de decisión**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118b2669",
      "metadata": {
        "id": "118b2669"
      },
      "source": [
        "### **Introducción**\n",
        "En este ejercicio vamos a analizar cómo la complejidad de un modelo de árbol de decisión puede llevar al fenómeno del **sobreajuste (overfitting)**.\n",
        "Para ello, entrenaremos múltiples modelos variando el hiperparámetro `max_depth` y evaluaremos su rendimiento tanto en el conjunto de entrenamiento como en el de validación.\n",
        "\n",
        "El objetivo es visualizar claramente cómo aumenta el error de validación cuando el modelo se vuelve demasiado complejo y deja de generalizar bien a nuevos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0abe9a",
      "metadata": {
        "id": "5c0abe9a"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Carga de librerías y configuración del entorno\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3b99fb",
      "metadata": {
        "id": "bb3b99fb"
      },
      "outputs": [],
      "source": [
        "# Celda 2: Cargar y explorar el dataset\n",
        "url = 'https://github.com/dtoralg/IE_Calidad_ML/raw/main/Data/control_calidad_piezas_metalicas.csv'\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f325898a",
      "metadata": {
        "id": "f325898a"
      },
      "outputs": [],
      "source": [
        "# Celda 3: Descripción del dataset\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbad0b2",
      "metadata": {
        "id": "acbad0b2"
      },
      "outputs": [],
      "source": [
        "# Celda 4: Preprocesamiento del dataset\n",
        "# Separar X e y\n",
        "...\n",
        "\n",
        "# Identificar columnas categóricas y numéricas\n",
        "...\n",
        "\n",
        "# Preprocesamiento con imputación y onehot encoding\n",
        "# Tip: Puedes usar un ColumnTransformer de la librería Pipeline para hacerlo\n",
        "# de forma más eficiente\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5da3fb",
      "metadata": {
        "id": "7f5da3fb"
      },
      "outputs": [],
      "source": [
        "# Celda 5: División en train y test\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0a2e2f",
      "metadata": {
        "id": "ba0a2e2f"
      },
      "outputs": [],
      "source": [
        "# Celda 6: Entrenamiento con diferentes profundidades\n",
        "# Crea un vector para almacenar los scores de train, otro para test.\n",
        "...\n",
        "depths = range(1, 21)\n",
        "\n",
        "for depth in depths:\n",
        "    clf = Pipeline([\n",
        "        ('preproc', ...),\n",
        "        ('model', ...)\n",
        "    ])\n",
        "    clf.fit(...)\n",
        "    y_train_pred = ...\n",
        "    y_test_pred = ...\n",
        "    # Rellena train scores con el F1 de las predicciones\n",
        "    train_scores.append(...)\n",
        "    test_scores.append(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b38937",
      "metadata": {
        "id": "28b38937"
      },
      "outputs": [],
      "source": [
        "# Celda 7: Visualización del sobreajuste\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(depths, train_scores, label='F1 Score - Entrenamiento', marker='o')\n",
        "plt.plot(depths, test_scores, label='F1 Score - Validación', marker='o')\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Curva de validación: Complejidad vs Rendimiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5f7ef5",
      "metadata": {
        "id": "bb5f7ef5"
      },
      "source": [
        "### **Conclusiones**\n",
        "- Al aumentar `max_depth`, el modelo mejora su rendimiento en el conjunto de entrenamiento, pero empieza a **perder capacidad de generalización** en el conjunto de prueba.\n",
        "- El punto donde la curva de validación (F1 Score en test) empieza a descender es una señal clara de **sobreajuste**.\n",
        "- Limitar la profundidad del árbol es una forma simple y efectiva de **regularización estructural**.\n",
        "\n",
        "### **Preguntas para reflexionar**\n",
        "- ¿Qué profundidad elegirías para este problema y por qué?\n",
        "- ¿Qué otras formas de regularización podrían aplicarse a árboles de decisión?\n",
        "- ¿Cómo podrías automatizar la búsqueda de la mejor profundidad?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}