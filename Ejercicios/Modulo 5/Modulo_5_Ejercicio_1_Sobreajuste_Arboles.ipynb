{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%205/Modulo_5_Ejercicio_1_Sobreajuste_Arboles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b4e208",
      "metadata": {
        "id": "69b4e208"
      },
      "source": [
        "### **Ejercicio 1: ¿Cuándo un modelo se está sobreajustando? Visualízalo tú mismo**\n",
        "**Diagnóstico visual del sobreajuste ajustando la profundidad de un árbol de decisión**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77c7e87a",
      "metadata": {
        "id": "77c7e87a"
      },
      "source": [
        "### **Introducción**\n",
        "En este ejercicio vamos a analizar cómo la complejidad de un modelo de árbol de decisión puede llevar al fenómeno del **sobreajuste (overfitting)**.\n",
        "Para ello, entrenaremos múltiples modelos variando el hiperparámetro `max_depth` y evaluaremos su rendimiento tanto en el conjunto de entrenamiento como en el de validación.\n",
        "\n",
        "El objetivo es visualizar claramente cómo aumenta el error de validación cuando el modelo se vuelve demasiado complejo y deja de generalizar bien a nuevos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8266eabf",
      "metadata": {
        "id": "8266eabf"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Carga de librerías y configuración\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79c09575",
      "metadata": {
        "id": "79c09575"
      },
      "outputs": [],
      "source": [
        "# Celda 2: Cargar el dataset\n",
        "url = 'https://github.com/dtoralg/IE_Calidad_ML/raw/main/Data/control_calidad_piezas_metalicas.csv'\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7807d6be",
      "metadata": {
        "id": "7807d6be"
      },
      "outputs": [],
      "source": [
        "# Celda 3: Preprocesamiento manual de la variable target\n",
        "...\n",
        "\n",
        "# Identificar variables categóricas y numéricas\n",
        "...\n",
        "\n",
        "# Imputar numéricas\n",
        "...\n",
        "\n",
        "# Codificar categóricas\n",
        "...\n",
        "\n",
        "# Escalar\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3156626",
      "metadata": {
        "id": "f3156626"
      },
      "outputs": [],
      "source": [
        "# Celda 4: División en entrenamiento y prueba\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b535ea87",
      "metadata": {
        "id": "b535ea87"
      },
      "outputs": [],
      "source": [
        "# Celda 5: Entrenamiento con diferentes profundidades\n",
        "# Usamos el modelo DecisionTreeClassifier\n",
        "# Podemos tomar el rango de depths que queramos\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "depths = ...\n",
        "for depth in depths:\n",
        "    clf = ...\n",
        "    clf.fit(...)\n",
        "    y_train_pred = ...\n",
        "    y_test_pred = ...\n",
        "    train_scores.append(...)\n",
        "    test_scores.append(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f1f453",
      "metadata": {
        "id": "c1f1f453"
      },
      "outputs": [],
      "source": [
        "# Celda 6: Visualización del sobreajuste\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(depths, ..., label='F1 Score - Entrenamiento', marker='o')\n",
        "plt.plot(depths, ..., label='F1 Score - Validación', marker='o')\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Curva de validación: Complejidad vs Rendimiento')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "199cdc03",
      "metadata": {
        "id": "199cdc03"
      },
      "source": [
        "### **Conclusiones**\n",
        "- Al aumentar `max_depth`, el modelo mejora su rendimiento en el conjunto de entrenamiento, pero empieza a **perder capacidad de generalización** en el conjunto de prueba.\n",
        "- El punto donde la curva de validación (F1 Score en test) empieza a descender es una señal clara de **sobreajuste**.\n",
        "- Limitar la profundidad del árbol es una forma simple y efectiva de **regularización estructural**.\n",
        "\n",
        "### **Preguntas para reflexionar**\n",
        "- ¿Qué profundidad elegirías para este problema y por qué?\n",
        "- ¿Qué otras formas de regularización podrían aplicarse a árboles de decisión?\n",
        "- ¿Cómo podrías automatizar la búsqueda de la mejor profundidad?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}