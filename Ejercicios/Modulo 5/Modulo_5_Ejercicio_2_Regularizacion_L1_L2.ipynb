{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%205/Modulo_5_Ejercicio_2_Regularizacion_L1_L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "784b377a",
      "metadata": {
        "id": "784b377a"
      },
      "source": [
        "### **Ejercicio 2: Regularización L1 vs L2 — ¿cuándo usar cada una?**\n",
        "**Explora cómo controlar el sobreajuste en modelos de regresión con Lasso y Ridge**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f254f1cf",
      "metadata": {
        "id": "f254f1cf"
      },
      "source": [
        "### **Introducción**\n",
        "En este ejercicio aprenderemos a utilizar técnicas de regularización para mejorar modelos de regresión. Compararemos **L1 (Lasso)** y **L2 (Ridge)** y observaremos cómo afectan a los coeficientes del modelo y al rendimiento en validación.\n",
        "\n",
        "La regularización es esencial para evitar el **sobreajuste**, especialmente cuando hay muchas variables o ruido en los datos. Evaluaremos también cuándo conviene usar L1, L2 o un modelo sin regularización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e9405c",
      "metadata": {
        "id": "87e9405c"
      },
      "outputs": [],
      "source": [
        "# Celda 1: Carga de librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.compose import ColumnTransformer\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9742f816",
      "metadata": {
        "id": "9742f816"
      },
      "outputs": [],
      "source": [
        "# Celda 2: Cargar el dataset\n",
        "url = 'https://github.com/dtoralg/IE_Calidad_ML/raw/main/Data/durabilidad_piezas.csv'\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c675194",
      "metadata": {
        "id": "1c675194"
      },
      "outputs": [],
      "source": [
        "# Celda 3: Preprocesamiento manual\n",
        "# Eliminar ID y separar variables\n",
        "...\n",
        "\n",
        "# Separar columnas categóricas y numéricas\n",
        "...\n",
        "\n",
        "# Imputar valores numéricos\n",
        "...\n",
        "\n",
        "# Codificar variables categóricas\n",
        "...\n",
        "\n",
        "# Escalar variables\n",
        "...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb83590d",
      "metadata": {
        "id": "cb83590d"
      },
      "outputs": [],
      "source": [
        "# Celda 4: División en train y test\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a804050",
      "metadata": {
        "id": "0a804050"
      },
      "outputs": [],
      "source": [
        "# Celda 5: Entrenamiento de modelos Linear, Ridge y Lasso\n",
        "modelos = {\n",
        "    'Linear': ...,\n",
        "    'Ridge': ...,\n",
        "    'Lasso': ...\n",
        "}\n",
        "resultados = {}\n",
        "\n",
        "for nombre, modelo in modelos.items():\n",
        "    modelo.fit(...)\n",
        "    y_pred = ...\n",
        "    mae = ...\n",
        "    rmse = ...\n",
        "    resultados[nombre] = {'MAE': mae, 'RMSE': rmse, 'coef': modelo.coef_}\n",
        "\n",
        "# Mostrar métricas\n",
        "pd.DataFrame(resultados).T[['MAE', 'RMSE']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05e7cfc3",
      "metadata": {
        "id": "05e7cfc3"
      },
      "outputs": [],
      "source": [
        "# Celda 6: Comparación de coeficientes\n",
        "coefs_df = pd.DataFrame({k: v['coef'] for k, v in resultados.items()})\n",
        "coefs_df.index = X.columns\n",
        "coefs_df.plot(kind='bar', figsize=(14,5))\n",
        "plt.title('Comparación de coeficientes entre Linear, Ridge y Lasso')\n",
        "plt.xlabel('Variables')\n",
        "plt.ylabel('Peso del coeficiente')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138214b1",
      "metadata": {
        "id": "138214b1"
      },
      "outputs": [],
      "source": [
        "# Celda 7: Evolución de coeficientes con alpha (parámetro que cuantifica la regularización)\n",
        "alphas = np.logspace(-2, 2, 20)\n",
        "lasso_norms, ridge_norms = [], []\n",
        "for alpha in alphas:\n",
        "    lasso = Lasso(alpha=alpha)\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    lasso.fit(X_train, y_train)\n",
        "    ridge.fit(X_train, y_train)\n",
        "    lasso_norms.append(np.linalg.norm(lasso.coef_))\n",
        "    ridge_norms.append(np.linalg.norm(ridge.coef_))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(alphas, lasso_norms, label='Lasso')\n",
        "plt.plot(alphas, ridge_norms, label='Ridge')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('Norma L2 de los coeficientes')\n",
        "plt.title('Regularización: efecto de alpha en los coeficientes')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7564cd71",
      "metadata": {
        "id": "7564cd71"
      },
      "source": [
        "### **Conclusiones**\n",
        "- La regresión lineal sin regularización puede sobreajustar en presencia de ruido o multicolinealidad.\n",
        "- **Ridge** reduce la magnitud de los coeficientes sin eliminarlos.\n",
        "- **Lasso** puede eliminar completamente variables, útil para simplificar el modelo.\n",
        "- El hiperparámetro `alpha` permite ajustar el grado de regularización.\n",
        "\n",
        "**Preguntas para reflexionar:**\n",
        "- ¿Cuál modelo ofrece mejor rendimiento general?\n",
        "- ¿Cuál sería más útil si necesitas un modelo explicable y compacto?\n",
        "- ¿Cómo automatizarías la búsqueda del mejor `alpha`?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}