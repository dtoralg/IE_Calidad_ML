{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9qdHeFA2dWar5xJjUKRen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%202/Modulo_2_Ejercicio_6_Resuelto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 6: Transformación y Feature Engineering\n",
        "\n",
        "## Objetivo\n",
        "En este ejercicio aprenderás a:\n",
        "- **Transformar variables numéricas:** Aplicar técnicas de normalización o estandarización a variables numéricas.\n",
        "- **Codificar variables categóricas:** Convertir variables categóricas en variables dummy (One-Hot Encoding).\n",
        "- **Crear nuevas características:** Generar variables derivadas a partir de las originales (por ejemplo, calcular el tamaño de la familia y definir si el pasajero viaja solo).\n",
        "\n",
        "Utilizaremos el dataset **Titanic**, que contiene información de los pasajeros. Algunas ideas de nuevas características son:\n",
        "- **FamilySize:** La suma de \"SibSp\" y \"Parch\" más 1 (para incluir al propio pasajero).\n",
        "- **IsAlone:** Variable binaria que indique si el pasajero viaja solo (FamilySize == 1).\n",
        "\n",
        "> **Pregunta de Reflexión:**  \n",
        "> ¿Cómo pueden las transformaciones de variables y la creación de nuevas features mejorar el desempeño de un modelo predictivo?  \n",
        "> ¿Qué ventajas encuentras al convertir variables categóricas en variables dummy?\n",
        "\n",
        "¡Manos a la obra!\n"
      ],
      "metadata": {
        "id": "iixRetW-B0cL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNAfnLbgBwYP"
      },
      "outputs": [],
      "source": [
        "# Paso 1: Importa las librerías necesarias y carga el dataset Titanic.\n",
        "\n",
        "# TODO: Importa pandas, numpy y, si lo consideras útil, las librerías para escalado y visualización.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define la URL del dataset Titanic (usaremos el dataset original de DataScienceDojo)\n",
        "url_titanic = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "\n",
        "# TODO: Carga el dataset utilizando pd.read_csv() y almacénalo en un DataFrame llamado 'df_titanic'\n",
        "df_titanic = pd.read_csv(url_titanic)\n",
        "\n",
        "# Muestra las primeras filas para verificar la carga\n",
        "print(\"Primeras filas del dataset Titanic:\")\n",
        "display(df_titanic.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 2: Aplica técnicas de escalado a variables numéricas.\n",
        "\n",
        "# Selecciona algunas variables numéricas de interés, por ejemplo: 'Age', 'Fare', 'SibSp' y 'Parch'.\n",
        "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "\n",
        "# TODO: Crea un DataFrame llamado df_numeric con solo estas columnas.\n",
        "df_numeric = df_titanic[numeric_features].copy()\n",
        "\n",
        "# Opcional: Si existen valores nulos en 'Age', imputalos con la mediana.\n",
        "if df_numeric['Age'].isnull().sum() > 0:\n",
        "    df_numeric['Age'].fillna(df_numeric['Age'].median(), inplace=True)\n",
        "\n",
        "# TODO: Aplica StandardScaler a df_numeric y almacena el resultado en un DataFrame llamado df_numeric_scaled.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df_numeric_scaled = pd.DataFrame(scaler.fit_transform(df_numeric), columns=numeric_features)\n",
        "\n",
        "print(\"Estadísticas descriptivas de las variables numéricas escaladas:\")\n",
        "display(df_numeric_scaled.describe())\n"
      ],
      "metadata": {
        "id": "hmiJQhm1B2wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Convierte variables categóricas en variables dummy.\n",
        "\n",
        "# Selecciona las columnas categóricas de interés, por ejemplo: 'Sex' y 'Embarked'\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "df_categorical = df_titanic[categorical_features].copy()\n",
        "\n",
        "# TODO: Aplica One-Hot Encoding a estas columnas usando pd.get_dummies(), eliminando la primera categoría para evitar la multicolinealidad.\n",
        "df_dummies = pd.get_dummies(df_categorical, drop_first=True)\n",
        "\n",
        "print(\"Primeras filas de las variables categóricas codificadas:\")\n",
        "display(df_dummies.head())\n"
      ],
      "metadata": {
        "id": "1vQtOwV-B33l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Genera nuevas características a partir de las variables originales.\n",
        "\n",
        "# Ejemplo 1: 'FamilySize' = SibSp + Parch + 1 (para incluir al pasajero)\n",
        "# TODO: Crea una nueva columna 'FamilySize' en el DataFrame df_titanic.\n",
        "df_titanic['FamilySize'] = df_titanic['SibSp'] + df_titanic['Parch'] + 1\n",
        "\n",
        "# Ejemplo 2: 'IsAlone' = 1 si FamilySize == 1, 0 en caso contrario.\n",
        "# TODO: Crea una nueva columna 'IsAlone' en df_titanic.\n",
        "df_titanic['IsAlone'] = (df_titanic['FamilySize'] == 1).astype(int)\n",
        "\n",
        "print(\"Primeras filas con las nuevas características 'FamilySize' e 'IsAlone':\")\n",
        "display(df_titanic[['FamilySize', 'IsAlone']].head())\n"
      ],
      "metadata": {
        "id": "6zKZLkELB5AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Integra las variables transformadas en un único DataFrame para modelado.\n",
        "\n",
        "# Selecciona las nuevas características que creaste: 'FamilySize' e 'IsAlone'\n",
        "new_features = ['FamilySize', 'IsAlone']\n",
        "df_new_features = df_titanic[new_features].copy()\n",
        "\n",
        "# TODO: Combina df_numeric_scaled, df_dummies y df_new_features en un DataFrame final llamado df_final.\n",
        "df_final = pd.concat([df_numeric_scaled, df_dummies, df_new_features], axis=1)\n",
        "\n",
        "print(\"Primeras filas del DataFrame final integrado:\")\n",
        "display(df_final.head())\n",
        "print(\"Información del DataFrame final:\")\n",
        "display(df_final.info())\n"
      ],
      "metadata": {
        "id": "9xpXGBC8B6w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 6 (Opcional): Aplica PCA para reducir la dimensionalidad del DataFrame final.\n",
        "# Esto te ayudará a visualizar la estructura de datos en 2 dimensiones.\n",
        "\n",
        "# TODO: Aplica PCA a df_final para reducirlo a 2 componentes.\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "df_pca = pd.DataFrame(pca.fit_transform(df_final), columns=['PC1', 'PC2'])\n",
        "\n",
        "# Muestra la varianza explicada de cada componente.\n",
        "print(\"Varianza explicada por cada componente PCA:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# Visualiza los resultados del PCA.\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x='PC1', y='PC2', data=df_pca)\n",
        "plt.title(\"Visualización PCA del DataFrame Final\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WhmT6LJ_B77Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 7: Sistema de testeo para validar las transformaciones y la integración.\n",
        "\n",
        "# Este bloque de código verificará:\n",
        "# 1. Que el DataFrame final (df_final) contenga las columnas esperadas:\n",
        "#    - Las variables numéricas escaladas: 'Age', 'Fare', 'SibSp', 'Parch'\n",
        "#    - Las variables dummy: (por ejemplo, 'Sex_male', 'Embarked_Q' o 'Embarked_S' según aparezcan)\n",
        "#    - Las nuevas características: 'FamilySize' e 'IsAlone'\n",
        "# 2. Que no existan valores nulos en df_final.\n",
        "# 3. (Opcional) Que el DataFrame PCA tenga 2 columnas.\n",
        "\n",
        "expected_numeric = ['Age', 'Fare', 'SibSp', 'Parch']\n",
        "expected_new = ['FamilySize', 'IsAlone']\n",
        "expected_columns = expected_numeric + list(df_dummies.columns) + expected_new\n",
        "\n",
        "for col in expected_columns:\n",
        "    assert col in df_final.columns, f\"Test fallido: La columna '{col}' no se encontró en el DataFrame final.\"\n",
        "\n",
        "assert df_final.isnull().sum().sum() == 0, \"Test fallido: Existen valores nulos en el DataFrame final.\"\n",
        "\n",
        "# Test opcional para PCA: El DataFrame resultante debe tener 2 columnas.\n",
        "assert df_pca.shape[1] == 2, \"Test fallido: El DataFrame PCA no tiene 2 componentes.\"\n",
        "\n",
        "print(\"Todos los tests se han pasado correctamente. Las transformaciones y feature engineering se realizaron como se esperaba.\")\n"
      ],
      "metadata": {
        "id": "NhK899HxB9CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflexión Final\n",
        "\n",
        "1. ¿Cómo crees que la creación de nuevas variables como 'FamilySize' e 'IsAlone' puede influir en la capacidad predictiva de un modelo?\n",
        "2. ¿Qué ventajas encuentras al aplicar técnicas de escalado a las variables numéricas antes de combinarlas con otras features?\n",
        "3. ¿Qué impacto tiene convertir variables categóricas en variables dummy para el análisis de datos?\n",
        "4. (Opcional) ¿Crees que la reducción de dimensionalidad con PCA es útil para visualizar la estructura del conjunto de datos? ¿Por qué?\n",
        "\n",
        "_Responde estas preguntas en una celda Markdown adicional o en un comentario._\n"
      ],
      "metadata": {
        "id": "0SQr0YzkB-Lw"
      }
    }
  ]
}