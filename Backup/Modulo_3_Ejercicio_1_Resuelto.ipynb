{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPnUnSZE9/hAefKtLMAo7v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Ejercicios/Modulo%203/Modulo_3_Ejercicio_1_Resuelto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1: Clasificación Supervisada en Juguetes\n",
        "\n",
        "## Objetivo\n",
        "En este ejercicio, aprenderás a construir un modelo de clasificación supervisada para predecir si un juguete pasa el control de calidad o no. Utilizaremos el dataset **control_calidad_juguetes.csv**. Para ello, realizarás lo siguiente:\n",
        "\n",
        "- Cargar el dataset y revisar sus características.\n",
        "- Definir una variable binaria (por ejemplo, \"Defectuoso\": 1 si la calidad es inferior a un umbral y 0 si es igual o superior).\n",
        "- Dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "- Entrenar un modelo de clasificación (por ejemplo, regresión logística).\n",
        "- Evaluar el rendimiento del modelo utilizando métricas como exactitud, matriz de confusión y ROC.\n",
        "\n",
        "¡Vamos a construir tu primer modelo de ML!\n"
      ],
      "metadata": {
        "id": "CFu-r4K-Rlbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXM6NTQWJMMr"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Cargar el dataset de calidad de juguetes\n",
        "df_juguetes = pd.read_csv('control_calidad_juguetes.csv')\n",
        "\n",
        "# Mostrar las primeras filas para verificar la carga\n",
        "print(\"Primeras filas del dataset de juguetes:\")\n",
        "display(df_juguetes.head())\n",
        "\n",
        "# Mostrar información general del DataFrame\n",
        "print(\"Información del dataset de juguetes:\")\n",
        "display(df_juguetes.info())\n",
        "\n",
        "# Mostrar estadísticas descriptivas\n",
        "print(\"Estadísticas descriptivas del dataset de juguetes:\")\n",
        "display(df_juguetes.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento: Crear una variable binaria para clasificar juguetes defectuosos\n",
        "# Supongamos que la columna 'Calidad' es una puntuación numérica y que consideramos defectuoso\n",
        "# un juguete si su calidad es inferior a un umbral (por ejemplo, 60).\n",
        "\n",
        "umbral = 60  # Puedes ajustar este valor según la distribución de 'Calidad'\n",
        "df_juguetes['Defectuoso'] = (df_juguetes['Calidad'] < umbral).astype(int)\n",
        "\n",
        "# Visualizar la distribución de la variable objetivo\n",
        "print(\"Distribución de la variable 'Defectuoso':\")\n",
        "print(df_juguetes['Defectuoso'].value_counts())\n"
      ],
      "metadata": {
        "id": "89QaLnRFRre1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjunto de entrenamiento y prueba.\n",
        "# Seleccionamos algunas variables que consideremos relevantes para la predicción.\n",
        "# Por ejemplo, usaremos 'Calidad', 'Defectos' y 'Costo' (si están disponibles).\n",
        "\n",
        "X = df_juguetes[['Calidad', 'Defectos', 'Costo']]\n",
        "y = df_juguetes['Defectuoso']\n",
        "\n",
        "# Dividir en entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Tamaño de X_train:\", X_train.shape)\n",
        "print(\"Tamaño de X_test:\", X_test.shape)\n",
        "\n",
        "# Entrenar un modelo de regresión logística\n",
        "modelo = LogisticRegression(solver='liblinear')\n",
        "modelo.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "DCwLBN5cRtf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = modelo.predict(X_test)\n",
        "y_proba = modelo.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular métricas de evaluación\n",
        "exactitud = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(\"Exactitud del modelo:\", exactitud)\n",
        "print(\"Matriz de confusión:\")\n",
        "print(cm)\n",
        "\n",
        "# Visualizar la curva ROC\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('Tasa de Falsos Positivos')\n",
        "plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "plt.title('Curva ROC del Modelo')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7M9ejJKYRvVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sistema de testeo: comprobaciones básicas\n",
        "\n",
        "# Test 1: Verificar que el DataFrame tiene registros\n",
        "assert df_juguetes.shape[0] > 0, \"Test fallido: El DataFrame está vacío.\"\n",
        "\n",
        "# Test 2: Verificar que las columnas 'Calidad', 'Defectos' y 'Costo' existen\n",
        "columnas_requeridas = ['Calidad', 'Defectos', 'Costo']\n",
        "for col in columnas_requeridas:\n",
        "    assert col in df_juguetes.columns, f\"Test fallido: La columna {col} no se encontró.\"\n",
        "\n",
        "# Test 3: Verificar que la variable 'Defectuoso' se creó correctamente\n",
        "assert 'Defectuoso' in df_juguetes.columns, \"Test fallido: La variable 'Defectuoso' no se creó.\"\n",
        "\n",
        "# Test 4: Verificar que el modelo tiene una exactitud razonable (por ejemplo, mayor al 60%)\n",
        "assert exactitud >= 0.6, f\"Test fallido: La exactitud del modelo es demasiado baja ({exactitud}).\"\n",
        "\n",
        "print(\"Todos los tests se han pasado correctamente.\")\n"
      ],
      "metadata": {
        "id": "ayEvsJA4RxbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflexión Final\n",
        "\n",
        "1. ¿Qué variables consideraste más relevantes para predecir si un juguete es defectuoso y por qué?\n",
        "2. ¿Cómo afecta la elección del umbral en la creación de la variable 'Defectuoso' a la distribución de clases?\n",
        "3. ¿Qué métricas de evaluación te parecen más importantes para este problema y por qué?\n",
        "4. ¿Qué mejoras podrías introducir en el preprocesamiento o en el modelo para aumentar la exactitud?\n",
        "\n",
        "_Responde estas preguntas en una celda Markdown adicional o en un comentario._\n"
      ],
      "metadata": {
        "id": "jLzXoEfWR0Ft"
      }
    }
  ]
}