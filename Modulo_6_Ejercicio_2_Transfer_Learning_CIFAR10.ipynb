{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtoralg/IE_Calidad_ML/blob/main/Modulo_6_Ejercicio_2_Transfer_Learning_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6676eb5",
      "metadata": {
        "id": "b6676eb5"
      },
      "source": [
        "**Ejercicio 2: Transfer Learning en Defectos Visuales de Producción con CIFAR-10**\n",
        "\n",
        "*Aplicar técnicas de transferencia de aprendizaje usando modelos preentrenados (como MobileNetV2) para clasificar imágenes industriales.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8807cab1",
      "metadata": {
        "id": "8807cab1"
      },
      "source": [
        "En este ejercicio aplicaremos una red neuronal convolucional preentrenada sobre el dataset CIFAR-10 para resolver una tarea de clasificación de imágenes.\n",
        "Primero construiremos una CNN básica como baseline, y luego aplicaremos Transfer Learning usando MobileNetV2.\n",
        "Evaluaremos el rendimiento con métricas de clasificación, curva de pérdida y matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e4b6d61",
      "metadata": {
        "id": "4e4b6d61"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ee70fea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ee70fea",
        "outputId": "2f5f31de-0ac0-4595-c13b-02555f1cc1eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "# Seleccionar solo dos clases para simplificar (por ejemplo: avión y automóvil)\n",
        "selected_classes = [0, 1]  # airplane vs automobile\n",
        "train_mask = np.isin(y_train, selected_classes).flatten()\n",
        "test_mask = np.isin(y_test, selected_classes).flatten()\n",
        "\n",
        "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
        "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
        "y_train = (y_train == selected_classes[1]).astype(int).flatten()\n",
        "y_test = (y_test == selected_classes[1]).astype(int).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c8367d4",
      "metadata": {
        "id": "5c8367d4"
      },
      "outputs": [],
      "source": [
        "# Preprocesamiento para MobileNetV2\n",
        "X_train_prep = preprocess_input(tf.image.resize(X_train, [96, 96]))\n",
        "X_test_prep = preprocess_input(tf.image.resize(X_test, [96, 96]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c61f88c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61f88c5",
        "outputId": "207227a2-96fe-4d5b-ab0b-2335917924ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.5506 - loss: 10.0922 - val_accuracy: 0.8215 - val_loss: 0.4904\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 76ms/step - accuracy: 0.6665 - loss: 0.5583 - val_accuracy: 0.8595 - val_loss: 0.3907\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.6851 - loss: 0.5210 - val_accuracy: 0.8520 - val_loss: 0.3691\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 68ms/step - accuracy: 0.7416 - loss: 0.4848 - val_accuracy: 0.8875 - val_loss: 0.3111\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.7782 - loss: 0.4406 - val_accuracy: 0.8905 - val_loss: 0.2950\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79721fa06090>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdg9Vsge1od7",
        "outputId": "6a314b03-c074-4699-c051-23d095d77624"
      },
      "id": "xdg9Vsge1od7",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90      1000\n",
            "           1       0.94      0.85      0.89      1000\n",
            "\n",
            "    accuracy                           0.90      2000\n",
            "   macro avg       0.90      0.90      0.90      2000\n",
            "weighted avg       0.90      0.90      0.90      2000\n",
            "\n",
            "[[943  57]\n",
            " [145 855]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "36d3ad8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36d3ad8e",
        "outputId": "1d38bdf1-ee1f-4e1e-b899-d5c975973519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 604ms/step - accuracy: 0.9154 - loss: 0.2040 - val_accuracy: 0.9780 - val_loss: 0.0562\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 527ms/step - accuracy: 0.9838 - loss: 0.0478 - val_accuracy: 0.9820 - val_loss: 0.0505\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 548ms/step - accuracy: 0.9893 - loss: 0.0309 - val_accuracy: 0.9785 - val_loss: 0.0573\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 559ms/step - accuracy: 0.9859 - loss: 0.0352 - val_accuracy: 0.9850 - val_loss: 0.0420\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 568ms/step - accuracy: 0.9883 - loss: 0.0266 - val_accuracy: 0.9835 - val_loss: 0.0414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79721ec9a5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "transfer_model = Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "transfer_model.fit(X_train_prep, y_train, epochs=5, validation_split=0.2, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6da2a55f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6da2a55f",
        "outputId": "8c8b5cf1-d897-4bd7-fc67-146ec514534d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 224ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98      1000\n",
            "           1       0.98      0.99      0.98      1000\n",
            "\n",
            "    accuracy                           0.98      2000\n",
            "   macro avg       0.98      0.98      0.98      2000\n",
            "weighted avg       0.98      0.98      0.98      2000\n",
            "\n",
            "[[979  21]\n",
            " [ 13 987]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = (transfer_model.predict(X_test_prep) > 0.5).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a83d7e5",
      "metadata": {
        "id": "4a83d7e5"
      },
      "source": [
        "**Conclusiones:**\n",
        "\n",
        "- El modelo preentrenado MobileNetV2 ha logrado buenos resultados con pocas épocas de entrenamiento.\n",
        "- Comparado con la CNN básica, ofrece mayor generalización y menor overfitting.\n",
        "- La transferencia de aprendizaje permite aprovechar conocimiento previo incluso en datasets pequeños."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247f6668",
      "metadata": {
        "id": "247f6668"
      },
      "source": [
        "**Próximos pasos:**\n",
        "- Afinar los hiperparámetros y usar `model_checkpoint` y `early_stopping`.\n",
        "- Descongelar capas del modelo base para realizar fine-tuning.\n",
        "- Aplicar técnicas de aumento de datos para mejorar la robustez del modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}